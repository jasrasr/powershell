{
  "date": "September 9, 2025\r",
  "episode_number": "1042",
  "show_notes": null,
  "full_text": "GIBSON RESEARCH CORPORATION\t\thttps://www.GRC.com/\r\n\r\nSERIES:\t\tSecurity Now!\r\nEPISODE:\t#1042\r\nDATE:\t\tSeptember 9, 2025\r\nTITLE:\t\tLetters of Marque\r\nHOSTS:\tSteve Gibson & Leo Laporte\r\nSOURCE:\thttps://media.grc.com/sn/sn-1042.mp3\r\nARCHIVE:\thttps://www.grc.com/securitynow.htm\r\n\r\nDESCRIPTION:  My experience with \"X\" vs. email.  Google TIG blackmailed to fire two security researchers.  1.1.1.1 DNS TLS certificate mis-issued.  Artists blackmailed with threats of training AI on their art.  Firefox extended end-of-life for Windows 7 to next March.  Is the renewal of cybersecurity info sharing coming soon.  Should security analysis be censored due to vibe coding.  UK vs. Apple may not be settled after all.  Another very serious supply chain attack.  Can the software supply-chain ever be trustworthy.  Why did BYTE Magazine die.  What happens if Google and others go on the attack?\r\n\r\nSHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He has a lot to talk about.  Why did BYTE magazine go out of business?  We think we might know.  A certificate authority who has completely destroyed security around 1.1.1.1 and why this happens.  Steve's got a good theory on this.  Are artists being blackmailed over using their art to train AI?  And then, finally, we're going to talk about using private companies to attack our nation's enemies.  Is that a good idea?  Cyberwarfare on the agenda.  All of that and more coming up next on Security Now!.\r\n\r\nLEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 1042, recorded Tuesday, September 9th, 2025:  Letters of Marque.\r\n\r\nIt's time for, yes, you waited all day for it, all week, Security Now!, the show where we cover your security, your privacy, your safety online.  And this is the man in charge, Mr. Steve Gibson.  Hi, Steve.\r\n\r\nSTEVE GIBSON:  Hello, Leo.  Great to be with you again as we are plowing through September.  And, oh, I forgot to update the date on the top of the show notes.  I'm looking at them right here.\r\n\r\nLEO:  I see it says September 2nd.  No, it's the 9th, my friend.\r\n\r\nSTEVE:  Right, 09/09/25.  But so just ignore that.  The number is correct.  I got that.  It's Episode 1042, titled \"Letters of Marque,\" spelled M-A-R-Q-U-E, which comes from some interesting evolution that we're going to talk about, which is, well, it's controversial.  I think, Leo, you and I are going to have a lot of fun talking about this at the end of the podcast.\r\n\r\nLEO:  I know what letters of marque are because I read the Patrick O'Brian/Aubrey Maturin series about a British man-of-war in the Napoleonic Wars.\r\n\r\nSTEVE:  Yup.\r\n\r\nLEO:  And it's a wonderful book series.  I don't know if you're familiar with it.  It's kind of like Horatio Hornblower.  These are two buddies.  He's the captain, Aubrey, and Maturin is his doctor.  And oh, my god, it's just a wonderful novel.  And one of them is actually called - it's 21 novels.  I've read them all.  One of them is actually called \"The Letter of Marque.\"  Interesting.\r\n\r\nSTEVE:  Ah.  Well, in this case we're going to explore the idea of our government permitting private corporations to go on the offense.\r\n\r\nLEO:  Yes, piracy.  In the days of Aubrey-Maturin it was piracy.  But, yeah.\r\n\r\nSTEVE:  Right.  Privateers, as they were called.\r\n\r\nLEO:  Yup.  Yup.\r\n\r\nSTEVE:  Because they were private enterprises who were also then, you know, being allowed to arm their ships.  Anyway, we're going to - I want to talk about sort of an update on my experience with X vs. email.\r\n\r\nLEO:  Oh, okay.\r\n\r\nSTEVE:  Since we now have a lot of baseline of results from that.  Google, their TIG group, their Threat Information Group or threat something group, is being blackmailed.\r\n\r\nLEO:  Oh, no.\r\n\r\nSTEVE:  To fire two security researchers.\r\n\r\nLEO:  Oh, please.\r\n\r\nSTEVE:  By a consortium, get this, a consortium of the well-known malicious actors that we've identified in the past.\r\n\r\nLEO:  What are they going to do to Google?\r\n\r\nSTEVE:  Well, they say they've got data that they're going to release.  Also the well-known 1.1.1.1 DNS TLS certificate was misissued.\r\n\r\nLEO:  Yes.\r\n\r\nSTEVE:  I have a theory as to why that I have not read in any of the coverage.  So maybe something new here.  Artists are being blackmailed with threats of training AI on their art because that would be bad.  Firefox announced the extension of its Windows 7 support.  Is the renewal of cybersecurity info sharing coming soon?  That was where cybersecurity, well, where private industry wanted to be able to share its events with the government, but there was a concern because this 10-year-long agreement is expiring at the end of the month.  What's happening with that?\r\n\r\nTrend Micro looks at whether security analysis should be censored now due to the emergence of vibe coding and how that shifts the difficulty of reimplementing - yeah, I know.  Also, it turns out that maybe UK vs. Apple's not settled after all, despite Tulsi Gabbard's tweet.  Also, oh, boy...\r\n\r\nLEO:  That's what we've come to, by the way, in the world.\r\n\r\nSTEVE:  I know.\r\n\r\nLEO:  Tulsi Gabbard's tweet.  Holy cow.  Holy cow.\r\n\r\nSTEVE:  I know.  And it would be nice to actually have some information about this.  But unfortunately, all of this is under mutual gag orders.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  So we're just all left to guess.  It's like, well, all you can do is, like, look at their actions and then infer what that presumably means.  So anyway, we have another very serious supply chain attack that causes us to look again at the problems, like the endemic problems we have with our current open source, repository-based, \"trust everybody\" supply chain.\r\n\r\nLEO:  I know which one you're going to talk about.  When I saw the number I was like, oh, this is bad.\r\n\r\nSTEVE:  There was an initial announcement, and then there was a follow-up.  So it'll be interesting to see which of those two you saw.  And we're going to wonder whether the whole system of our current approach can ever be trustworthy.  Also we've got some interesting editorial from the editor of why exactly BYTE magazine died.  I'm going to mostly just give people a link to that because he has a very interesting FAQ.  And then we're going to look at what happens if Google and others go on the attack because Google announced just over - it was a little bit before last week, during a conference about this topic, that they were going to be creating a division for that.\r\n\r\nLEO:  Oh, no.\r\n\r\nSTEVE:  Yes.\r\n\r\nLEO:  Oh, no.  I don't know if I like that at all.\r\n\r\nSTEVE:  Yes.  We're going to have an interesting time talking about that, Leo, at the end of the podcast.  But not until we look at one of the best Pictures of the Week we have had in a long time.\r\n\r\nLEO:  Oh.\r\n\r\nSTEVE:  Which you haven't - you've said you have not looked at yet.  So our audience will get the opportunity to hear you.  This is one of those you will get instantaneously.  And, oh, it's a goodie.\r\n\r\nLEO:  All right, Mr. G.  I am ready.\r\n\r\nSTEVE:  So before you look, I need to tell you that I gave this picture the title \"Have you ever wondered whatever became of Microsoft's Clippy?\"\r\n\r\nLEO:  All right.\r\n\r\nSTEVE:  Have you ever wondered...\r\n\r\nLEO:  I have.  I have.\r\n\r\nSTEVE:  ...whatever became of Microsoft's Clippy.\r\n\r\nLEO:  Let's scroll up.\r\n\r\nSTEVE:  We have the answer.\r\n\r\nLEO:  Oh, oh, I see, I see, oh, oh.  He's hard at work; isn't he.  Holy cow.  That was - that is pareidolia in an unusual form.\r\n\r\nSTEVE:  Isn't that great?  It's, I mean, it looks so much like Microsoft's Clippy.  Anyone who was ever assaulted by him on, what was that, Office?  I think it was.\r\n\r\nLEO:  Well, I think it was all of Windows.\r\n\r\nSTEVE:  Oh, okay.\r\n\r\nLEO:  Yeah.  You will have PTSD for sure if you - the funny thing is this is a toilet paper holder.\r\n\r\nSTEVE:  Yes.\r\n\r\nLEO:  In a bathroom.\r\n\r\nSTEVE:  Yes.  Somebody took, it looks like a steel rod, and bent it in a very clever shape to be able to have a toilet paper roll perch on its extension and sort of extrusion.  And then against the wall is - it is secured to the wall by two Phillips head screws through the rod, which really does...\r\n\r\nLEO:  Looks like eyeballs.\r\n\r\nSTEVE:  Bring one back to Clippy.  So...\r\n\r\nLEO:  But you hope, though, Dr. [Du] said this, is it's not saying, hey, I see you're trying to - oh, never mind.  Oh, never mind.  By the way, the toilet paper has run out.  Which is pretty much the way it worked with Clippy, as well.\r\n\r\nSTEVE:  That's right.  That's right.\r\n\r\nLEO:  Wow.  That is a good one.  You're right.\r\n\r\nSTEVE:  I just got a kick out of that.  So just a heads-up that between last week and this week, my blue checkmark on X was taken away.  It's gone.\r\n\r\nLEO:  Oh, no.  Now, you didn't pay for it in the first place; right?  Or did you?\r\n\r\nSTEVE:  I think I did.  A year ago when I had the choice.  And so I presume that my yearly premium subscription just expired.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  And I'm pleased that I was not automatically charged for another year without my knowledge or permission.\r\n\r\nLEO:  See, I have a free one that I don't really want.\r\n\r\nSTEVE:  Why?\r\n\r\nLEO:  Because at some point Elon went through the list of people with lots of followers and decided some people deserve a blue check whether they pay for it or not.  Which I kind of like because it gives me access to Grok Pro and all of that.\r\n\r\nSTEVE:  Yeah.  And I remember a year ago thinking, oh, what the heck, you know.  But the problem is we're not a year ago.  Since its inception, GRC's email system has proven to be a total success.\r\n\r\nLEO:  Yes.\r\n\r\nSTEVE:  And at the time it was brand new.  Last Monday afternoon, which is to say yesterday, the email system sent out 18,465 podcast summary emails, each one containing the short bullet-pointed episode summary, the Picture of the Week, and a link to the complete show notes.  All 18,465 pieces of email were delivered, with none bouncing for any reason other than out-of-office auto reply, or mailbox full, or an arguably unavoidable reason.  And so sending weekly mass mailings is now free and effortless.  Costs me nothing.  And it's, I mean, it's just literally, I just press a couple buttons because I did take the time to automate the whole process.  So also between that Monday and our last podcast, and Sunday afternoon, two days ago, when I'm writing this, I have received, so like over the past week, I've received 97 pieces of terrific feedback mail from our listeners.\r\n\r\nNow, by comparison, while I do still receive some wonderful pieces of Pictures of the Week ideas from a couple of longtime associates over on X, including that's where this week's wonderful picture came from, I no longer receive any feedback of much other value through X.  It only comes through email.  And so that's a huge change from 10 years ago, when all of our podcast feedback was coming to me through X, through DMs, because as you used to tell everybody, I have open DMs.  Anybody can send me a DM, even though I'm not following them because I don't follow anybody.  I would just use X as a broadcast medium.  So today email makes far more sense.  You know, and I see when @SGgrc is mentioned, it appears in my timeline.  But they look like sort of generic conversations involving other people who just sort of mention me in a list of people that they're wanting to mention.  So they're not of much value, either.\r\n\r\nSo, you know I will continue to post the weekly show notes to X as I have been, you know, ever since the world called it Twitter.  And that was 15 years ago, when I registered @SGgrc back in 2010.  But I don't feel like paying X $7 per month for the privilege of having a blue checkmark, because basically that's all it means.  You know, I'm able to, you know, get messages out to our audience.  Anybody who wants to is able to sign up.  And, you know, you're nice enough to remind everybody, Leo, every week that they can go to GRC.com/mail in order to sign up.  So anyway.  And the other thing, too, I guess I'm old-school.  Actually, I know I am.  But I was never able to feel completely comfortable receiving or replying to someone who chose the moniker \"Stinky Bits\" over on X.  That's just, I don't know, that's just not me.\r\n\r\nSo anyway, while I was writing this, actually while I was writing this I received a piece of feedback through email with the subject line \"An apology,\" he says, \"(although it's kind of your fault), and a Thank You.\"  This was our listener, John Wayward, who wrote:  \"Steve, I have to apologize for missing the last three episodes of Security Now!.\"  Well, you know, he doesn't have to apologize to me.  I wasn't hurt by him missing them; right?\r\n\r\nBut he said:  \"However, it's kind of your fault.  I typically listen on long car journeys each week between London and Plymouth.  However, after your repeated recommendations of 'Project Hail Mary,' I downloaded the audiobook and have been absolutely addicted to it.  I have listened to nothing else.  WHAT a book.  Thank you so very much for the recommendation.  Just wow.  I'm now going to go back and listen to 'The Martian,' albeit in slower time, with Security Now! mixed in, too.\"  Well, we'll see about that.  He may get similarly addicted.  He said:  \"I don't know how the movie can possibly match up to the 'science the crap out of it' detail of the book, but I'm excited for it nonetheless.  All the very best.  I now have three SNs to catch up on.  John.\"\r\n\r\nSo anyway, you know, as I said, in years past I would receive feedback like that through X, but I suspect that those listeners have moved, as I and John have, to email.  So anyway, I just wanted to give everybody an update.  My presence at X is nominal, and email is really the place to have interaction with me these days.  It doesn't cost you anything.  If you ask me, if you tell me you want to be anonymous, you've heard me anonymize our listeners who don't want to be identified.  That's fine.  I'm happy to honor that.  And it's just, you know, it's a smoother medium.  And I don't talk about the fact that I'm also responding to a lot of the feedback that I get, just quickly back through email, thanking people or acknowledging that I've read their note and so forth.  So anyway, thank you all for the connection through email.  It really, I think, helps the podcast to be a lot more of a live thing than it would otherwise be.\r\n\r\nOkay.  So here's a weird one.  Cyber Security News reports that Google is effectively being extorted to terminate the employment of two of its employees.  And the more you learn about this, the weirder it gets.  Here's what is being reported by Cyber Security News.  They wrote:  \"A group claiming to be a coalition of hacking groups has issued an ultimatum to Google, threatening to release the company's databases unless two of its employees are terminated.  The demand, which appeared in a Telegram post, named Austin Larsen and Charles Carmakal, both members of Google's Threat Intelligence Group, TIG.  In addition to that, according to a post seen by Newsweek, the self-proclaimed hacking collective which calls itself\" - get this - \"'Scattered LapSus Hunters,'\" which is a conglomeration of their names, right, \"also insisted that Google suspend all investigations by its Threat Intelligence Group into the network's activities.\"\r\n\r\nLEO:  I'd give those two guys a raise.  I think this is a testimony to their effectiveness.\r\n\r\nSTEVE:  Yeah.  So this group apparently feels that they've got the goods on Google.  So they're saying, \"Terminate these guys, and you must stop investigating us.\"  And so the group's name, they write, \"is an apparent reference to its composition, which it claims includes members from established hacking communities such as Scattered Spider, LapSus, and ShinyHunters.\"  Thus the hybrid name Scattered LapSus Hunters.  \"So far, the group has not provided any evidence to substantiate its claim of having accessed Google's databases.  Furthermore, there have been no recent confirmed breaches of Google's internal information systems.\r\n\r\n\"This threat emerges, however, in the wake of a separate incident disclosed by Google in August.  The company confirmed that ShinyHunters\" - remember they're the big phishing group that are seeing so much success through phishing - \"ShinyHunters, one of the groups allegedly part of the new coalition, had successfully obtained data from Salesforce.  Salesforce, being a third-party vendor, provides various services to Google, and the breach occurred within the vendor's systems, not Google's own infrastructure.\r\n\r\n\"The formation of a supergroup such as 'Scattered LapSus Hunters,'\" they write, \"would represent a significant escalation in the cyberthreat landscape.  Scattered Spider is known for its sophisticated social engineering tactics, while LapSus gained notoriety for its aggressive high-profile attacks on major tech companies.  And ShinyHunters has a long history of large-scale data breaches and selling stolen information on the dark web.  The potential collaboration of these entities could pose a formidable challenge to even the most well-defended corporations.\"  So, you know, pooling skilled resources is not something that we would like to have happen.  But...\r\n\r\nLEO:  This extortion thing is just out of control.\r\n\r\nSTEVE:  It just never stops.  It is a mess, yeah.  \"Newsweek has reportedly reached out to Google for a statement regarding the alleged threats, but a response was not immediately received as the request was made outside of standard business hours.\"  And this news just broke.  \"The situation remains under observation as the tech community awaits Google's official response and further developments.\"  So...\r\n\r\nLEO:  Well, they're not going to fire somebody because that is ridiculous.\r\n\r\nSTEVE:  No, no.  The only - it is.  You're absolutely right.  There's no way that they're going to put this group of malicious criminals in charge of their human resources branch.\r\n\r\nLEO:  In fact, it's an endorsement for those guys.  I mean, if these guys want them to get rid of them, they must be good.\r\n\r\nSTEVE:  They must be doing something right, exactly.\r\n\r\nLEO:  Yeah.\r\n\r\nSTEVE:  So anyway, we're just going to need to wait and watch.  And as you said, Leo, I cannot imagine that Google could possibly capitulate in any way to this group, or any group, regardless of what the group might have obtained that Google might well wish to remain private.  If anything, the proper response would be for them to turn up the heat on the various members of the group to cause them to regret ever floating the threat.\r\n\r\nLEO:  Yes.  Yes.  There you go.  Don't like that.\r\n\r\nSTEVE:  Don't threaten us or else.\r\n\r\nLEO:  Yeah.\r\n\r\nSTEVE:  Okay.  So certificate authorities, our trust in their proper actions, and the chains of trust they anchor is crucial to so much of the operation of the Internet that this podcast has spent a great deal of time through its two decades of reporting examining the protocols, the technologies, and the operation of every aspect of the certificate trust system.  You know, we followed my fascination with the challenge of certificate revocation.  It turns out that once a certificate has been issued, it's surprisingly difficult to \"un-issue\" it, due to the way the entire system functions.\r\n\r\nOver the past 20 years we've followed the industry flip-flopping back and forth as it tries one thing after another.  It abandoned the original certificate revocation lists (CRLs) in favor of online certificate status protocol (OSCP), then came up with a better solution for CRLs using Bloom filters, which we talked about previously, and then abandoned OCSP over its privacy concerns.  So who knows what...\r\n\r\nLEO:  If you listen to this show, you're an expert in this whole endless saga...\r\n\r\nSTEVE:  That's true.\r\n\r\nLEO:  ...of certificate revocation.  Oy.\r\n\r\nSTEVE:  Yeah.  It is true.  And in fact I wrap up today's podcast sharing how uncomfortable the whole topic of cyberwar makes me, for one reason.  There's, you know, it's above our pay grade, Leo.  You know, like there's a lot that we don't know about what's going on.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  And I'm so much more comfortable being able to talk about hard technology, like okay, this is how this works.  This is what this does.  This is why it's broken and so forth.  So, you know, it's where we're going to stay.  At the same time, what's happening on the cyberwar front is important.  So we're going to talk about it today.  But, you know, it just leaves me feeling queasy.  Whereas being able to talk about, okay, here is the cool technology of a Bloom filter, which frankly our listeners feel the same way.  We got so much feedback about all of our deep dive podcasts through the years.\r\n\r\nSo anyway, given how difficult revocation has proven to be, it's good news that certificates are not often mis-issued, considering how many there are and how often with increasing frequency now due to the fact that the CA/Browser Forum keeps restricting how long they're allowed to live, how often they're being reissued.  We don't see that much trouble.  A great deal of time, talent, and attention has gone into securing the issuing process.\r\n\r\nAnd, for example, we recently looked at how certificate authorities are now being required, that is, they're requiring themselves, because they're part of this coalition, to perform domain control checks of servers from several widely dispersed vantage points to prevent them from being misled by any sort of local attack on their own bandwidth where they were only verifying domain ownership and control from a single vantage point.  That would represent a single point of failure.  So the lesson here is that the certificate authority industry has gone to great lengths to assure that certificates are never mis-issued.\r\n\r\nGiven that revocation remains challenging, and that mis-issuance is avoided at all costs, the news of three certificates being misissued - and it turns out it was more than three, but we'll get there - for as prominent a domain as 1.1.1.1 is both surprising and worrisome.  So what happened, and how did it happen?  So here's what's been reported so far by Ars Technica.\r\n\r\nThey wrote:  \"People in Internet security circles are sounding the alarm over the issuance of three TLS certificates for 1.1.1.1, a widely used DNS service from content delivery network Cloudflare and the Asia Pacific Network Information Centre (APNIC) Internet registry.  The three certificates, issued in May, can be used to decrypt domain lookup queries encrypted through DNS over HTTPS or DNS over TLS.\"  That's because, you know, DNS over UDP, old-school DNS, doesn't use certificates.  It's not encrypted, and it's not authenticated.  Both DNS over HTTPS and DNS over TLS use TCP connections over TLS, which provides privacy and verification of who you're connecting to.  Unless it's a fraudulently released certificate.  And that's the concern here.\r\n\r\nArs wrote:  \"Both protocols provide end-to-end encryption when end-user devices seek the IP address of a particular domain they want to access.  Two of the certificates remained valid at the time this post went live on Ars.\"  And that was last Wednesday, September 3rd, when Ars wrote this.  \"Although the certificates were issued four months ago, their existence came to public notice only on Wednesday,\" that is, last Wednesday, \"in a post to an online discussion forum.  They were issued by Fina RDC 2020, a certificate authority that's subordinate to the root certificate holder Fina Root CA.  The Fina Root CA, in turn, is trusted by the Microsoft Root Certificate Program, which governs which certificates are trusted by the Windows operating system.  Microsoft Edge accounts for approximately 5% of the browsers actively used on the Internet.\r\n\r\n\"In an emailed statement sent several hours after this post went live, Cloudflare officials confirmed the certificates were improperly issued.\"  Meaning they didn't issue them.  They own that domain.  Any certificates that were going to be issued for 1.1.1.1 had to be done by them.  \"Cloudflare wrote in part:  'Cloudflare did not authorize Fina to issue these certificates.  Upon seeing the report on the certificate-transparency email list, we immediately kicked off an investigation and reached out to Fina, Microsoft, and Fina's TSP supervisory body - who can mitigate the issue by revoking trust in Fina or the mis-issued certificates.  At this time, we have not yet heard back from Fina.'\"\r\n\r\nArs wrote:  \"Microsoft said in an email that it has 'engaged the certificate authority to request immediate action.  We're also taking steps to block the affected certificates through our disallowed list to help keep customers protected.'\"  Ars wrote:  \"The statement didn't say how the company failed to identify the improperly issued certificate for such a long period of time.  Representatives from Google and Mozilla said in emails that their Chrome and Firefox browsers have never trusted the certificates\" - meaning anything from Fina - \"and there was no need for users to take any action.  An Apple representative responded to an email with this link to a list of certificate authorities Safari trusts.  Fina was also not included.\"\r\n\r\nSo, okay.  That's interesting.  For whatever reason, Microsoft and thus Windows has been trusting any certificates issued by this apparently flaky certificate authority; whereas Google, Mozilla, and Apple all apparently never saw the need.  Ars wrote:  \"It wasn't immediately known which organization or person requested and obtained the credentials.  Representatives from Fina did not answer emails seeking details.\"\r\n\r\nAs I was reading this I had the thought that perhaps Fina should be renamed \"fini,\" and the industry should just be done with them.  What's curious is why Microsoft appears to be pussy-footing around with these clowns.  I certainly would not want my Windows OS to be trusting any certificate that Fina might issue, which it currently does.  I mean, Microsoft trusting Fina, I mean, and this is what we talked about a long time ago, one of the mixed blessings of the CA system that we have, and it bears everybody remembering this, all of the CAs that we trust are trusted regardless of what they sign, meaning that any certificate authority we trust is allowed to sign a certificate for any property, any domain.\r\n\r\nLEO:  Right.  Even if they don't own it.\r\n\r\nSTEVE:  So even if they - exactly.  Just as Fina did.  Fina has nothing to do with 1.1.1.1.  I imagine Cloudflare never even heard of them or considered them.  Yet there are valid certificates for Cloudflare's domain that have been issued.  So similarly, the fact that Windows is trusting these clowns means that everybody running Windows trusts anything that Fina signs as being legitimate. \r\n\r\nThen Ars Technica continues to provide a bit more additional background, writing:  \"The certificates\" - and this is stuff we know, but it's worth covering.  \"The certificates are a key part of the Transport Layer Security protocol.  They bind a specific domain to a public key.  The certificate authority, the entity authorized to issue browser-trusted certificates, possesses the private key certifying that the certificate is valid.  Anyone in possession of a TLS certificate can cryptographically impersonate the domain for which it was issued.\"\r\n\r\nOkay, now, we know that's all true, thus the power of a certificate and why the industry has gone to and goes to such lengths to make sure only the signatures of trustworthy entities are trusted.  That is, only the signatures of trustworthy CAs.  Ars explains:  \"The holder of the 1.1.1.1 certificates could potentially use them in active adversary-in-the-middle attacks that intercept communications passing between end users and the Cloudflare DNS service.  From here, attackers with possession of the 1.1.1.1 certificates could decrypt, view, and tamper with traffic from the Cloudflare DNS service.\"  All true.\r\n\r\nArs wrote:  \"Wednesday's discovery exposes a key\" - pardon the pun - \"weakness of the public key infrastructure that's responsible for ensuring trust of the entire Internet.  Despite being the only thing ensuring that gmail.com, bankofamerica.com, and any other website is controlled by the entity claiming ownership, the entire system can collapse with a single point of failure.\"  Again, sobering but true.\r\n\r\nCloudflare's statement observed - so Cloudflare weighed in on this also, of course, and we quoted them earlier in the Ars piece.  They said:  \"The CA ecosystem is a castle with many doors.  The failure of one CA can cause the security of the whole castle to be compromised.  CA misbehavior, whether intentional or not, poses a persistent and significant concern for Cloudflare.  From the start, Cloudflare has helped develop and run Certificate Transparency that has allowed this mis-issuance to come to light.\"  On the other hand, not very quickly, which we're going to be getting to that in a second.\r\n\r\nArs adds:  \"The incident also reflects poorly on Microsoft for failing to proactively catch the mis-issued certificates and allowing Windows to trust them for such a long period of time.  Certificate Transparency, a site that catalogues in real time the issuance of all browser-trusted certificates, can be searched automatically.  The entire purpose of the certificate transparency logs is so stakeholders can quickly identify mis-issued certificates before they can be actively used.  The mis-issuance in this case is easy to spot because the IP addresses used to confirm the party applying for the certificates had control of the domain was 1.1.1.1 itself.  The public discovery of the certificates four months after the fact suggests the transparency logs did not receive the attention they were intended to get.  It's unclear how so many different parties could miss the certificates for such a long time span.\"\r\n\r\nAll that's right.  The next day, which was last Thursday the 4th of September, Cloudflare themselves, the owner, the rightful owner of the domain 1.1.1.1, and as such the only entity that should be able to issue certificates, posted their own piece about this under their headline \"Addressing the unauthorized issuance of multiple TLS certificates for 1.1.1.1.\"  I'm only going to share the top of their posting, but I've placed a link to the entire thing in the notes.  Cloudflare summarizes the situation by writing:  \"Over the past few days Cloudflare has been notified through our vulnerability disclosure program and the certificate transparency mailing list that unauthorized certificates were issued by Fina CA for 1.1.1.1, one of the IP addresses used by our public DNS resolver service.\"\r\n\r\nThen they write, get this:  \"From February 2024\" - okay, not this past February 2025, February 2024 - \"to August 2025, Fina CA issued 12 certificates for 1.1.1.1 without our permission.  We did not observe unauthorized issuance for any properties managed by Cloudflare other than 1.1.1.1.  We have no evidence,\" they wrote, \"that bad actors took advantage of this error.  To impersonate Cloudflare's public DNS resolver 1.1.1.1, an attacker would not only require an unauthorized certificate and its corresponding private key, which the issuer would have, but attacked users would also need to trust the Fina CA.\"  True.  \"Furthermore, traffic between the client and 1.1.1.1 would have to be intercepted.\"  All correct.  So first of all, that means only Microsoft clients, and there'd have to be an adversary in the middle.\r\n\r\nLEO:  So somebody's asking, if you didn't use a Microsoft Edge browser, if you used Chrome or Firefox, you wouldn't be at risk.\r\n\r\nSTEVE:  Mozilla brings their own.  Chrome is now using - I believe Chrome is now using Windows.  For a while the Chromium had their own.  But, for example, Chromium and Bing, I believe they're both now using Microsoft's Root Store.  There's been some change with Chrome over time.  And I may be out of sync with that.\r\n\r\nLEO:  I also wonder, if you don't want to do a union of the two certificate sets, only because there may be local certificates trusted by the operating system the browser doesn't know about; right?\r\n\r\nSTEVE:  Right.\r\n\r\nLEO:  So it seems to me that you would want to, as a browser, trust both the set that you brought to the table, but also the set offered by the operating system in case there's, you know...\r\n\r\nSTEVE:  Right.  And in fact the...\r\n\r\nLEO:  ...AD domains and stuff.\r\n\r\nSTEVE:  The root stores do have essentially a directory hierarchy that allows you to put your own local roots in a separate location.\r\n\r\nLEO:  And I presume you could also edit the Fina roots out.\r\n\r\nSTEVE:  Yes.  You are able to delete them.  Although every Windows Update refreshes that list.\r\n\r\nLEO:  Replaces them.  Oh, great.\r\n\r\nSTEVE:  Yeah.  So Cloudflare said:  \"While this unauthorized issuance is an unacceptable lapse in security by Fina\" - I mean, and really they ought to just be booted out of any root store - \"we should have caught,\" they're saying, Cloudflare is saying, \"we should have caught and responded to it earlier.\"  Like yeah.  Last February a year ago.  A year and a half ago.  Eleven certs this has happened to.\r\n\r\nThey said:  \"After speaking with Fina CA, it appears that they issued these certificates for the purposes of internal testing.  However, no CA should be issuing certificates for domains and IP addresses without checking control.  At present, all certificates have been revoked.  We are awaiting a full post-mortem from Fina.  While we regret this situation, we believe it is a useful opportunity to walk through how trust works on the Internet...\"\r\n\r\nLEO:  It's a teaching moment, that's what it is.\r\n\r\nSTEVE:  Exactly.  We're all going to learn a lesson from this.  So anyway, the rest of their post that I have a link to in the show notes goes through that, for anybody who's interested.  And one of the things that Cloudflare shares is a list of all the various domains that were present in these 11 certificates.  We see there fina.hr, ssltest5 with no top-level domain on it, test.fina.hr, test.hr, test1.hr, test11.hr, test12.hr, test5.hr, test6 with no TLD, test6.hr, testssl.fina.hr, testssl.finatest.hr - I only have a few more - testssl.hr, testssl1.finatest.hr and testssl2.finatest.hr.\r\n\r\nLEO:  The point is they all have \"test\" in the name; right?\r\n\r\nSTEVE:  Yes.  Looking at that list, and thinking about what Cloudflare wrote, after speaking with Fina CA, it appears that they issued these certificates for the purposes of internal testing.  I would bet a month's pay that the reason 1.1.1.1 appeared in any Fina-issued test certificate is for the same reason Cloudflare chose it as the name and address of their DNS service.  It is super short, easy to enter, and easy to remember.  In other words...\r\n\r\nLEO:  It's why so many people's passwords are 1.11111111; right?\r\n\r\nSTEVE:  Yes.  I would happily wager...\r\n\r\nLEO:  Did I just break Steve?\r\n\r\nSTEVE:  ...that at no point - are you there?  Hello?  Huh.\r\n\r\nBENITO:  Hi, Steve.  I'm not sure what happened to Leo.\r\n\r\nSTEVE:  Okay.  Everything looks good here.  And I don't know if you know.  He was having all kinds of weird problems this morning, you know, at the beginning of MacBreak Weekly.\r\n\r\nBENITO:  Oh, I didn't know that.\r\n\r\nSTEVE:  Yeah, I think he had a power failure, and his stuff had not recovered.  And so they were trying to set the conference up, their communication up in some particular way, but they ended up falling back to something different.\r\n\r\nBENITO:  [Indiscernible] Starlink or something.  Unless he lost power, and then I don't know what...\r\n\r\nSTEVE:  The last thing I heard him say was \"Did I break Steve?\"  And that was when it looks like we broke Leo, actually.\r\n\r\nBENITO:  Yeah, Anthony's saying it might be a power outage. \r\n\r\nSTEVE:  Yeah, he had said that they had installed two new 20-amp circuits.  I guess he's putting a load on the amp now.\r\n\r\nBENITO:  We turned everything off for that.\r\n\r\nSTEVE:  Yeah, he had - I guess he's up in the attic, I think, of his new place, or that place, and then I think that it wasn't powered for the amount of equipment...\r\n\r\nBENITO:  Oh, he's back.\r\n\r\nSTEVE:  Yay.\r\n\r\nBENITO:  Oh, no, it's Anthony.  Oh, sorry.  I tried to turn you on.  There you go.  Hey, Anthony.\r\n\r\nANTHONY:  Can you hear me?\r\n\r\nBENITO:  Yup.\r\n\r\nSTEVE:  Yup, I hear you.\r\n\r\nANTHONY:  Yeah, you might want to, unless he was going to do an ad right now, maybe like continue on with the story, and then hopefully he'll...\r\n\r\nSTEVE:  Yeah, okay.  Will do.  I think that makes the most sense.\r\n\r\nANTHONY:  Okay.\r\n\r\nSTEVE:  So, yeah, I would bet a month's pay that the reason 1.1.1.1 appeared in any Fina-issued test certificate is for the same reason Cloudflare chose it as the name and address of their DNS service.  It is super short, easy to enter, and easy to remember.  In other words, I would happily wager that at no point was any of this mis-issuance in any way malicious.  You know, some tech guy inside Fina was just playing around with issuing test certificates and the numeric-only IPv4 domain 1.1.1.1 was super quick and easy to enter.\r\n\r\nNow, having said that, the big no-no was that these test certificates were being signed with the same private key that Microsoft and also the EU's Trust Service Provider, those are the two entities we know of who trust this Fina CA.  They both trusted anything signed with that private key.  That should never have been done, even though Fina says, and I am inclined to believe them, that none of those certificates ever left their control.  It's still unnerving that they were created.  And so it would certainly have been possible to be using a test private key to sign those test certificates, which is in no one's root store, in which case no one would have a complaint.  They'd just be like doing purely internal testing.  The mistake they made was in using the publicly trusted, even though with limited trust, Microsoft and this EU organization only.  Still, that should have never happened.\r\n\r\nLEO:  How did - so if they're using it for testing, why would they make it public?\r\n\r\nSTEVE:  Right.  So, well, they didn't.  What happened was the way the certificate transparency system works is that down in the automation of the signing of any certificate, the act of signing a certificate sends the event into the common public certificate transparency log.  So, you know, and what this highlighted is that certificate transparency logs, which we went to all this trouble to create and to maintain, no one's looking at them.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  So, you know, so Cloudflare ought to have an automated process that is looking at the logs and checking to make sure that, you know, no certificates appear in them that are for domains they control.  And frankly, you know, I could be doing that.  GRC, if I was worried about somebody issuing a certificate in my name, I would have something that was scanning the logs, checking to make sure that GRC.com didn't, you know, wasn't issued by anyone anywhere at any time.\r\n\r\nLEO:  So this really underscores how - what a position of trust being a CA authority is. \r\n\r\nSTEVE:  Yes.\r\n\r\nLEO:  I mean, it's very powerful.\r\n\r\nSTEVE:  And again, it's one of the things that we spend a lot of time looking at because it's a fascinating aspect of the way the Internet works; right?  And we've seen CAs lose the ability to sign certificates when they abuse the privilege.  Basically, as I've put it before, they're being allowed to print money.\r\n\r\nLEO:  Yeah.\r\n\r\nSTEVE:  We're saying, hey, you get to print money, basically for signing some bits that people present you.  In return, you have to do so responsibly.\r\n\r\nLEO:  Yeah.  There.\r\n\r\nSTEVE:  Really interesting case.  But I think that, you know, at first, you know, the first time you hear about it, it's like, 1.1.1.1 certificates were, like, maliciously created.  It's like...\r\n\r\nLEO:  It sounds malicious, yeah.\r\n\r\nSTEVE:  Yeah.  Or it's easy to imagine because it would be bad.  But probably just, you know, just a techie, you know.  As you said, Leo, it's why passwords are 1111111.\r\n\r\nLEO:  Right.  It's not just a techie.  It was practically an intern.  I mean, it was obviously some low-level nitwit who didn't know, first of all, that they'd be automatically published.  Right?\r\n\r\nSTEVE:  Right.  Right.  Although they've been doing since last February, and nothing happened.  So Cloudflare, you're not checking your logs, are you.\r\n\r\nLEO:  Yeah, but who does?  I don't.  You don't.  We don't.\r\n\r\nSTEVE:  No.\r\n\r\nLEO:  No.  I mean, Cloudflare needs to.  That seems the most important thing.  All right, Steve.\r\n\r\nSTEVE:  So this appears to be the week for wacky events.  Here's another one.\r\n\r\nLEO:  Oh, boy.\r\n\r\nSTEVE:  Bad guys have cooked up a new way to extort artists by threatening to submit their stolen original artwork to AI for training.\r\n\r\nLEO:  Oh, that's hysterical.  Oh, my gosh.\r\n\r\nSTEVE:  I'm not kidding.  The ransomware group LunaLock compromised a commission-based web platform that connects artists with clients.  The group said that if it was not paid a ransom on time, it would share the data with AI companies, thus adding all of the artists' work to their massive large language model data sets.\r\n\r\nLEO:  Benito says, \"They're trying to extort broke artists?  You picked the wrong people to extort, buddy.\"\r\n\r\nSTEVE:  Yeah, I doubt there's much money at that site.  On August 30th, a message appeared on the Artists & Clients website stating that it had been hacked by a ransomware group.  One of the website's users noticed the message and shared the news on Reddit.  They were redirected to a page with a ransom note, indicating that all the databases and files, including all of the artwork, had been stolen and encrypted.  In return for the stolen data, the group is asking $50,000.\r\n\r\nThey had a little, like a nice little web page with selectable dropdown expandable FAQ items.  One of them says, I have it in the show notes:  \"This is my website.  What if I don't pay the ransom?\"  And the answer is:  \"All files, including personal user data, will be leaked on various dark web forums and torrents.  Artwork will be submitted to AI companies for inclusion in training datasets.\"  So anyway, I suppose that the genesis of this is that some bad guys hacked into a not very super secure website that matches up clients with artists where artists have their portfolios online for perusal, and clients are then able to submit offers to commission original works.  And actually this logo that I've got here, the SQRL logo, came from such a site.  That's how I had that made.\r\n\r\nLEO:  Yeah.  Nice.  Yeah, yeah.\r\n\r\nSTEVE:  So, wow.  Again, wacky stuff.  Last Thursday, Mozilla posted the headline \"Extended Firefox ESR 115 Support for Windows 7, 8, and 8.1, and macOS 10.12-10.14.\"  They wrote:  \"Mozilla has continued to support Firefox on Windows 7, Windows 8, and Windows 8.1 long after these operating systems reached end of life, helping users extend the life of their devices and reduce unnecessary obsolescence.\"  I like that term, \"unnecessary obsolescence.\"  They said:  \"We originally announced that security updates for Firefox ESR 115 would end in September 2024\" - so a year ago - \"later extending that to 2025, this month. \r\n\r\n\"Today, we are extending support once again:  Firefox ESR 115 will continue to receive security updates on Windows 7, 8, and 8.1 until March of 2026.\"  So six months from now.  They said:  \"This extension gives users more time to transition while ensuring critical security protections remain available.  That's the key.  We still strongly encourage upgrading to a supported operating system to access the latest Firefox features\" - because those are not being updated - \"and maintain long-term stability.  Note that this extension is also applicable for macOS 10.12-10.14 users running Firefox ESR 115.\"\r\n\r\nNow, I, for one, appreciate this since I'm still spending my days in front of a Windows 7 machine - actually that's what I'm in front of right now - which is working quite well.  And I need to confess, or at least update everyone, that since that last version of the Brave browser that supported Windows 7 was released way back on January 25th of 2023, so we're coming up on three years old, three years ago, after using Brave for a while and appreciating its clear commitment to honoring my privacy, I have returned to trusty old Mozilla Firefox.\r\n\r\nSo Mozilla's announcement that they will be keeping my Firefox 115, which is what I use here, patched for another six months is welcome news.  I'm sure they have telemetry, which actually is interesting feedback, right, that's informing them that I am not alone in continuing to run their lovely Firefox web browser on Windows 7.  Or I'm not using 8 and 8.1, but I can imagine people are.  Also, as someone who has written at least my fair share of Windows apps, I'll take a moment to just note, this whole notion of an app caring all that much about which platform it's running on, like which platform version it's running on is at least a bit overblown.  When I opened up the DNS Benchmark source code to begin working on its version 2, I discovered, somewhat to my amusement, that it would run on every version of Windows, that is, GRC's DNS Benchmark, on every version of Windows from Windows 95 through Windows 11.\r\n\r\nMicrosoft goes to great lengths to not break old applications on new editions of Windows.  So Windows 95 would have been, what, 1995?  So that's a 30-year span of Windows.  All this nonsense about no longer supporting an operating system because the OS platform itself is not supported is, as I said, quite overblown.\r\n\r\nBut I expect that my Windows 7 machine will be retiring at year's end.  Everybody who's watching the videos of this podcast will see my location change as I consolidate two locations into a new third location.  And at that time, given how long I tend to keep my cars and my computers - and for that matter my iPads and my Palm Pilots - I fully expect that I will be setting up what will become my final PC.  And that one will be running Windows 10, which is where I'm going to be staying.\r\n\r\nAs I've noted before, the two greatest attack surfaces of our PCs are email - where we make the mistake of clicking on a sour link - and our web browsers, whether we go somewhere malicious directly by mistake, or by clicking a link and following a link that we receive in email.  So these days I am far more glad to be running web browsers and email clients that are, as my old version of Firefox still is and will be for another six months, being kept up to date and secure than an operating system that was deliberately abandoned by its publisher many years ago.  So there.\r\n\r\nSo we recently noted that private industry had begun withholding information from the federal government over its concern that the blanket information-sharing protections provided by the 10-year long so-called Cybersecurity and Information Sharing Act of 2015 - which would be expiring at the end of this month of September - might not be renewed.\r\n\r\nLEO:  Uh-oh.\r\n\r\nSTEVE:  Uh-huh.  This 10-year duration Act allows private sector providers to freely share cyberthreat intelligence with government partners under the guarantee of liability protections.  We've talked about this before, Leo.  A lot of the so-called critical infrastructure is privately owned and run.  You know?\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  You know, it's the electricity grid, and the Internet itself is, you know, that's all private ownership.  So it's important for the government to and the private sector to be able to compare notes and confess when there's a problem without worrying...\r\n\r\nLEO:  Yes, without going to jail, yes.\r\n\r\nSTEVE:  Yes, exactly.  So unless this Act is renewed by Congress - which has not yet happened, and we only have three weeks and counting, or remaining - the Act's expiration would mean that a vital source of cybersecurity intelligence for our government would dry up overnight because, you know, already there's been some, oh, like, whoops, we can't talk about this because we're not sure we're going to get protected.\r\n\r\nNextGov offers some interesting background about the Act, its past and the hurdles it currently faces in today's quite messy Washington climate.  Under their headline \"House panel advances bill to extend bedrock cyber info-sharing law,\" they then lead with the tease \"Some Republicans want to ensure there's language that would prevent the nation's core cyberdefense agency from engaging in alleged 'censorship' of Americans' free speech.\"  So, you know, this concern that CISA was getting itself involved in, you know, was being accused of election interference previously.  And so there are some Republicans who are saying okay, well, we want to take this opportunity to fix that.\r\n\r\nSo anyway, Nextgov wrote:  \"The House Homeland Security Committee on Wednesday\" - which is last Wednesday - \"approved a measure that would renew a cornerstone cybersecurity law designed to optimize the exchange of cyberthreat information between the private sector and U.S. government.\"  Okay.  So that's the House Homeland Security Committee, which is a committee, obviously of the House, but then this still has to go through both houses of Congress.  So they said:  \"The original law, the Cybersecurity and Information Sharing Act of 2015, lets private sector providers freely transmit cyberthreat intelligence to government partners with key liability protections in place.  It's set to lapse September 30th unless renewed by Congress.\r\n\r\n\"The extension, dubbed the Widespread Information Management for the Welfare of\" - oh, my lord.  It's the WIMWIG, the WIMWIG.  \"The WIMWIG Act is Widespread Information Management for the Welfare of Infrastructure and Government, the WIMWIG Act, extends the law another 10 years and now moves to the full House for consideration.\"  Why don't they just make it permanent law?  I mean, then we wouldn't have this problem.  They could always amend it or adjust it if they wanted to.  But having these deadlines, everyone has to scramble around.  Anyway, I'm not there.\r\n\r\nThey wrote:  \"Technical amendments were introduced to the bill, which were met with little pushback in committee.  Top of mind for some Republicans on the panel were concerns that the Cybersecurity and Infrastructure Security Agency (CISA) would be enabled to censor Americans' protected speech.  That concern extends to the Senate Homeland Security Committee, where Chairman Rand Paul, a First Amendment hawk, has said he would add language in the Senate's version of the reauthorization that would bar CISA from carrying out alleged censorship of free speech.\"  Although actually under CISA's current management that doesn't seem to be a problem, but okay.\r\n\r\n\"CISA has faced mounting Republican criticism over allegations of censorship tied to its efforts to combat election-related disinformation in and around 2020.  GOP lawmakers contend this amounted to unconstitutional government pressure on private companies to suppress speech, particularly conservative viewpoints.  In the early 2010s, legislative efforts to establish a cyberthreat information sharing framework had been underway for several years\" - back then, right, now, 2010, that's not today, so a lot has changed in the last 15 years - \"but back then,\" they said, \"faced major hurdles amid public skepticism over government privacy abuses following Edward Snowden's 2013 global surveillance disclosures.\r\n\r\n\"That view, however, shifted after the Office of Personnel Management suffered that massive security breach in 2015, which compromised the personal information of over 21 million current and former federal employees.\"  Whoops.  \"This galvanized support for the law as it stands today.\"  You know, so there was the government saying why didn't we - why weren't we told about this?  Well, it turns out the private industry had some information that they were afraid to share because they didn't want to get in trouble.  So a law was created that said it's okay, you can tell us.  We promise not to be mad.\r\n\r\nThe article finishes:  \"Stakeholders say the liability protections in the data-sharing law are critical because they shield companies from lawsuits and regulatory penalties when sharing cyberthreat indicators with the government.  Oftentimes, cyberthreat data includes specific names of individuals or sensitive business information, depending on what hackers target.\r\n\r\n\"Robert Mayer, U.S. Telecom's senior vice president of cybersecurity and innovation\" - so he's a classic private sector guy, right, he's the guy who would want to be able to share things with the government - \"said:  'By reauthorizing the law, this bill preserves the trusted framework that enables industry and government to share critical threat information quickly and securely.  For the telecomm sector, where our networks are on the front lines of cyber defense, this legislation is essential to protecting the infrastructure Americans depend on every day.\"\r\n\r\nSo the renewal of the bill, largely as written, would appear to be of vital importance.  And, you know, even today, even more so than 10 years ago when it was first passed, we need this.  So I expect that within a few weeks we'll be observing its passage through both houses of Congress, and that President Trump will then sign it into law, and that will be good for everyone.  But it hasn't happened yet.  And, you know, the politicians want to take this opportunity, especially something that everybody understands has to pass in order to squeeze their amendments in and get the provisions added that they need.  So, but still, I expect it to happen.\r\n\r\nOh, this is really interesting.  Trend Micro decided to test whether today's availability of AI-assisted code generation, you know, popularly known as \"vibe coding,\" changes the balance to weigh against the security community's longstanding practice of publicly disclosing and sharing their detailed analysis of known attack code, strategies, and malware.  We know that when proofs of concept are made public, those who might never have been able to create such attacks from scratch themselves are suddenly empowered with the ability to do so.  So the very real concern and question which Trend Micro wanted to ask was, does AI's ability to generate code change this equation?  And actually I've even, Leo, heard the term \"prompt kiddies.\"\r\n\r\nLEO:  Yeah.  Well, sure, yeah.\r\n\r\nSTEVE:  Yeah.  So here's what Trend Micro wrote and what they did.  They said:  \"Security companies routinely publish detailed analyses of security incidents, making attacker techniques, tactics, and procedures (TTPs), tactics, techniques, and procedures, widely known and visible.  These reports often provide comprehensive insights into specific vulnerabilities that are or could be exploited, malware delivery mechanisms, and evasion techniques.  This transparency is crucial for the cybersecurity community, enabling organizations to understand the evolving threat landscape so they can implement more effective defenses for themselves.  But it has evolved into a double-edged sword.\r\n\r\n\"The benefits of detailed security publications significantly outweigh the risks,\" they contend.  For example:  \"Providing defenders with up-to-date TTPs enables proactive security measures.  Building awareness across the security community strengthens collective defenses.  Developing and improving security platforms and detection capabilities is critical.  Enabling threat intelligence sharing benefits the entire ecosystem.  And supporting incident response teams with actionable intelligence enhances their effectiveness.\"  So lots of things over on the pro side of this that are benefits to an industry that is open and sharing what it finds.\r\n\r\nThey wrote:  \"It's not a secret that attackers follow security blogs and read posts about them and other threat actors.  The Conti leaks - which is to say leaks from inside Conti - for example, contain several discussions of such public posts.\"  So in Conti they were talking about public posts.  \"They often learn from these posts about the defenders' techniques and use this information to evolve and improve their own attacks.\r\n\r\n\"To test whether our industry's practice of providing detailed TTPs enables the creation of malware itself, we conducted an experiment.  Using Trend Micro's published analysis of the Earth Alux (A-L-U-X) threat actor espionage toolkit, we attempted to recreate similar capabilities using AI-assisted 'vibe coding.'\r\n\r\n\"In this experiment, we used Claude AI (Claude-4-Opus) in combination with Visual Studio Code and Cline.  The platform readily began generating code that simulated the attacker's communication patterns, including the emulation of a first-stage backdoor, persistence mechanisms, and the attacking components.\r\n\r\n\"Upon initial inspection, this approach was very straightforward.  Bypassing antimalware creation guardrails was quite trivial using a number of uncensored models readily available in platforms like Hugging Face.\"  In other words, you can't ask ChatGPT, but you can use uncensored platforms.  They said:  \"The first version was generated in Python, and for the sake of flexibility we regenerated the code in C.\r\n\r\n\"But did it resemble the original code?  Yes.  But only up to the point of how much was disclosed in the actual blog post.  More importantly, while even more detailed technical reports helped large language models generate even more accurate code, the generated code itself was not perfect.  For most security reports, some level of skill and understanding of the code will still be needed to finalize that code into a working tool.  The AI provides a significant starting point, but technical expertise remains essential for creating functional malware.\"\r\n\r\nAnd I'll just interject here to note that, what is it, it is September 9th, 2025.  Remember our byword here is anything, anytime we are ever talking about anything to do with AI, you need to timestamp the conversation because it ain't going to be true in 90 days, or 180 days.  So in fact, Leo, I'm sure you'll be talking about this tomorrow on Intelligent Machines, but OpenAI just released a report where they believe they now understand why AI hallucinates.  And to test their hypothesis, they changed the way they trained a ChatGPT 5 mini model and eliminated hallucination.  So...\r\n\r\nLEO:  Yeah, they say it's a bug, in effect; right?  Yeah.\r\n\r\nSTEVE:  Yeah.  Actually, a perfect example is, if you asked it what someone's birthday was, well, even if it didn't know, if it guessed a random day, it has a one out of 365 chance of being right, which is better than saying \"I don't know,\" which is zero.\r\n\r\nLEO:  Yeah, that's logical.\r\n\r\nSTEVE:  And so they have inadvertently trained it to guess because they reward answers more than they reward it saying \"I don't know.\"\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  And as our listeners know, \"I don't know\" is one of my favorite phrases because that's the start of going to find out.\r\n\r\nLEO:  Right, right, right.\r\n\r\nSTEVE:  Rather than guessing.  So I've told the story many times.  I had, back in the early days of GRC, a really neat techie that was working with me on the early versions of SpinRite.  And he just - he had this propensity for guessing what a bug was.  And I said - his name was James.  And I said, \"Well, James, maybe.  But now we have a problem because now your ego is involved in something that is not a subject of ego.  There's a bug.  We need to find it.  Now you want to be right, and I just want to find the bug.  So I don't know why there's a bug, and you don't either.  But now you have a vested interest.  So it's much easier, it's much better just to say 'I don't know,' and 'Let's go find out.'\"\r\n\r\nSo anyway, I thought it was interesting.  And so the point is here we're talking about this; right?  And these guys are saying, you know, Trend Micro is saying, well, you know, it's not good enough to be, to allow prompt kiddies to create malware.  But again, September 9th, 2025.  Probably not 2026.\r\n\r\nSo they said:  \"Having highlighted the risks of AI-assisted code generation, we must also consider how this capability muddies the waters for attribution.\"  Ah, that's interesting.  \"The ability to directly copy malware characteristics described in security reports creates significant challenges for threat hunters and investigators.  Attribution has always been challenging in cybersecurity.\"  Right?  Whodunit?\r\n\r\n\"Attackers have long employed various techniques to confuse investigators, such as:  Software component reuse:  Using tools associated with other groups.  Infrastructure reuse:  Deliberately using domains and hosts linked to other threat actors.  TTP mimicry:  Copying the operational patterns of other groups.  False flags:  Deliberately adding misleading artifacts, such as North Korean APT groups adding Russian-language artifacts to their binaries.  And living-off-the-land techniques:  Using only tools available on target machines\" to just not give anyone a clue.\r\n\r\nSo they wrote:  \"With vibe coding tools, creating copycat campaigns becomes significantly easier.  Even nonprogrammers can build a somewhat functional code by providing simple text instructions.  This democratization of malware development poses new challenges for developers.\"\r\n\r\nThey said:  \"We've already observed that some APT groups have become early adopters of AI and LLM technologies.  This trend will likely accelerate as vibe coding tools  which support the rapid prototyping of software based on textual descriptions  continue to evolve.  Two key issues with security blogs in the world of AI today are:  They ease the process for attackers to copy the techniques of other groups and quickly get up to speed; and they muddy attribution efforts when analysts rely solely on TTPs or indicators of compromise.\r\n\r\n\"So should threat publication stop?  No.  Threat publication is more critical than ever, but it does need to adapt.  For our fellow defenders and the broader industry, this means criminal adoption of AI complicates cybercrime defense.  Our industry needs to be more active than ever in educating and supporting our readership.  LLM-generated code from blogs is a good start for an attacker, but it's not perfect.  Publishers should factor in the ways that LLMs could possibly be misused during the publication process and test how their detailed descriptions might be exploited.\"  So in other words, while authoring and publishing technical security research, keep in mind now that AI will almost certainly also be ingesting that research, and you may be seeing signs of it in the future.\r\n\r\nThey wrote:  \"Vibe code copying muddies attribution, although this only applies for those with a primitive view of attribution based solely on TTPs or IoCs (Indicators of Compromise).  We recommend best practices using more sophisticated attribution which must evolve beyond simple indicator matching.  Publications remain essential.  Security publications are a side effect of the research developed to enable leading security platforms to defend.  Those same platforms will always be the first line of defense.  The knowledge sharing that occurs through these publications strengthens the entire security ecosystem.\"\r\n\r\nThat is, you know, all of the security companies cross-sharing the result of their research so they don't all individually have to research everything.  I mean, it's perfect, you know, community functioning.  And Trend is saying we depend upon it, so we provide it.  In other words, while it's true that the bad guys will gain, so, too, will the good guys from this publication.  But it does make things more difficult.\r\n\r\nThey finish, saying:  \"Vibe coding (or vibe programming) represents a paradigm shift in software development through AI-assisted code generation.  This approach significantly simplifies and speeds up the process of writing executable code, removing barriers for nonprogrammers.  However, as we've demonstrated, it also empowers 'prompt kiddies' (individuals without deep technical knowledge) to misuse the technology for wrongdoing.\r\n\r\n\"In this article, we've only scratched the surface of the use and possible abuse of vibe coding generative tools for malicious purposes.  The evolution of these tools creates new challenges for threat hunters and defenders.  Simple and blind correlation of attacks by matching TTPs will no longer be effective.\"  Because there's going to be TTP (Tactics, Techniques, and Procedures) blurring as a consequence of this because large language models are going to be incorporating all this.\r\n\r\nThey said:  \"Defenders will need to embrace leading methods of attack clustering and attribution based on the attackers' intentions, objectives, and targeting.  Shifting attribution techniques to focus on the primary objectives of the attacker might make it harder for attackers to plant false flags.  That said, security is always a cat-and-mouse game; and with every step forward, we evolve into another cycle of innovation and adaptation.\"\r\n\r\nSo basically, as I've been summarizing through this, the security firms are going to continue publishing with the knowledge that large language models are going to be training on this publicly available information, and that bad guys are going to be given a big of a leg up through vibe coding, just like all other programmers are.  And that it will mean that, because code is actually coming out of LLMs rather than out of specific coders, the habits of specific coders, which were being reflected by their code, I mean, I guarantee you, if you look at my code, you can tell it's me.\r\n\r\nLEO:  You would know, yeah, yeah.\r\n\r\nSTEVE:  Yes.  There are things I do over and over and over, you know, my so-called \"patterns of coding,\" which absolutely fingerprint me as the author of that code.  And I'm sure that that is, like - and, you know, we don't see that talked about publicly.  But what Trend Micro is saying is they've been using that.  They similarly pick up on code approaches that they see in the disassembly of malware, and they're able to say, oh, we know that that came from Vladimir.  \r\n\r\nLEO:  It's a signature, yeah, sure.\r\n\r\nSTEVE:  Yeah, it is.  And, you know, my code clearly carries my own signature.  I'm well aware of that.  And so if code largely now comes out of LLMs, and then is tweaked in order to fix it where it doesn't quite work, then you're not going to have, you know, that same code signature showing.  Really interesting.\r\n\r\nLEO:  Or it might be somebody else's code signature that the LLM learned when ingesting their code.\r\n\r\nSTEVE:  My guess is it would get blurred, I think, I mean, because it's going to be sucking in so much code and homogenizing it, essentially.  So, yeah.\r\n\r\nLEO:  Yeah, probably.  Yeah, yeah.\r\n\r\nSTEVE:  Some reporting I encountered after I recounted a tweet made by the current U.S. Director of National Intelligence, Tulsi Gabbard, which in all fairness didn't really provide anything more than a somewhat nondescript boast, appears to have been incorrect, at least according to some newer information.  Unfortunately, I don't maintain a subscription to the Financial Times, but it is - and, boy, they are, like, very powerfully paywalled now.  But the Financial Times is a credible source of information.  So all I can do, again, is share what I have found, which reads as follows.\r\n\r\n\"The fight between Apple and the UK government over lawful access to iCloud user data has not been resolved, despite media reporting last week.  The Financial Times this week reported on documents filed with the Investigatory Powers Tribunal, an independent judicial body that examines complaints about UK intelligence services.\"  Okay.  So we knew that Apple was going to appeal to the UK's Investigatory Powers Tribunal, so that's not news.  But perhaps the fact that this is still ongoing, at least as of last week, means that the issue is not yet as resolved as we may have believed.\r\n\r\nThe reporting continues:  \"Back in January, Apple was provided\" - and we know this - \"with a government order known as a Technical Capability Notice (TCN).  The Financial Times now suggests the TCN required Apple to provide broad access to iCloud data, including messages and passwords.\"  I don't know if we knew about that.  \"The obligations included in the TCN are not limited to the UK or users of the service in the UK.\"  Well, that we did know.  \"They apply globally in respect of the relevant data categories of all iCloud users,\" the IPT filing adds.  Okay.  But that's not news either.  We knew all that.  Again, the point might be that the Financial Times is reporting on a leak from the supposedly secret Tribunal.  The reporting about this finishes with the sentence:  \"So despite what Tulsi Gabbard says on social media, this is still a live issue.\"\r\n\r\nOkay.  So I'm thoroughly confused.  My intention here was just to take back what was reported a week or two ago.  I don't have any firsthand or even secondhand knowledge of what Tulsi Gabbard may or may not know.  So perhaps our takeaway should be to take tweets for what they are, remembering also what they are not, which is anything definitive and actionable.  And again, the problem is Apple can't say anything because they're under a gag order.  All we know is that I guess we have the Financial Times reporting that they have in fact filed with the Tribunal.  Whether that means they're closing the loop, crossing their T's and dotting their I's, I don't know.  Again, we don't know.  But I just wanted to mention that it may not be resolved, which is unfortunate because we want it to be resolved.\r\n\r\nOkay.  We have a very serious supply-chain attack.  And Leo, let's take our second-to-last break before we get into our main topic because...\r\n\r\nLEO:  Oh, good.  Okay.\r\n\r\nSTEVE:  ...I want to spend some time on this.\r\n\r\nLEO:  I do subscribe to the Financial Times.\r\n\r\nSTEVE:  Ah, good.\r\n\r\nLEO:  I do have - I have the article here.  They say they saw the legal filing.  And as you said, according to the legal filing, they wanted access to all of the standard iCloud stuff, which we know Apple does have the keys to.\r\n\r\nSTEVE:  I don't think I knew that they had people's passwords.  To me that's a little surprising because...\r\n\r\nLEO:  Yeah, I don't know if they do.  I mean, you can ask for it, but Apple could say, well, sorry, we don't have it.\r\n\r\nSTEVE:  Yeah.\r\n\r\nLEO:  If you use Apple's password manager, your passwords are synced to iCloud.\r\n\r\nSTEVE:  That's right.  It's in the Keychain, presumably.  \r\n\r\nLEO:  But I don't know if Apple has the key to that.  They shouldn't.  That should be generated on your local device using the Secure Enclave, and not available to Apple at all.  Maybe when they said \"passwords\" they meant Apple's, you know, the customer's password to their Apple account.  I don't know.\r\n\r\nSTEVE:  Or the ability to unlock the phone.  I mean, I can see, we know that Apple's able to unlock the phone.  But that's a little different than saying, yeah, we actually [crosstalk].\r\n\r\nLEO:  Is Apple able to unlock the phone?  We do know that?\r\n\r\nSTEVE:  I think we do.\r\n\r\nLEO:  See, I feel like that those kinds of things should be generated on-device and stored in Secure Enclave and not available to Apple.\r\n\r\nSTEVE:  Yeah.\r\n\r\nLEO:  I don't know.  I'll have to look.  Yeah.  And the fact that this is ongoing tells us that whatever DNI Gabbard said, it's not over.\r\n\r\nSTEVE:  Not resolved yet.  And that is the message I wanted to convey.\r\n\r\nLEO:  Yeah, yeah.\r\n\r\nSTEVE:  That there is some doubt now about what was previously tweeted.  So we're going to, you know, unfortunately we're back on tenterhooks because, you know, this needs to get fixed.\r\n\r\nLEO:  Well, anybody who lives in the UK doesn't have the advanced protection anyway because Apple did withdraw that.\r\n\r\nSTEVE:  Well, they can't turn it on.  Did they do an update and take it away?\r\n\r\nLEO:  Oh, I wonder.  You're right.  If it was previously turned on.\r\n\r\nSTEVE:  Yeah.\r\n\r\nLEO:  Oh, that's an interesting question.  Yeah, you can't do it - oh, that's - no, I doubt Apple retroactively would disable it.  But who knows?\r\n\r\nSTEVE:  Yeah.  \r\n\r\nLEO:  This is all a mystery because none of this is exposed.  It's all...\r\n\r\nSTEVE:  Yes, it's all just little random leaks from the corners, yeah.\r\n\r\nLEO:  Right. \r\n\r\nSTEVE:  Okay.  So first we're going to talk about what happened, and then about the problem.  This is another illustration of just how vulnerable the open source software system is to, sadly, malicious abuse.  The announcement of what one developer discovered was posted on Substack with the title \"We Just Found Malicious Code in the Popular Error-Ex NPM Package.\"  The developer wrote:  \"Before you read any further, go to the website for the npm package error-ex.  Look at the number of weekly downloads.  You will likely see a number north of 47 million.\"  Okay, 47 million downloads per week.\r\n\r\nLEO:  It's right now 49 million.\r\n\r\nSTEVE:  Yeah.  And if you put your cursor on that little bump, you'll see that I think it's 67 or something, if it's live.  It was live on mine.\r\n\r\nLEO:  What little bump?  What are you talking about?\r\n\r\nSTEVE:  In the chart, when I did it, that chart was live.\r\n\r\nLEO:  Oh, oh, oh, I see what you're saying, yeah, yeah, yeah.\r\n\r\nSTEVE:  There it is.  There it is.\r\n\r\nLEO:  Oh, at one point it was 60, 64, 62 million, 64.7.\r\n\r\nSTEVE:  Yup, 64.7, yup.\r\n\r\nLEO:  Wow.  So it goes up and down.\r\n\r\nSTEVE:  Well, that's per week; right?  Okay.  So this guy wrote:  \"This isn't a headline-grabbing framework like React or Express.  It's a tiny, one-line utility package, buried deep within the dependency trees of tens of thousands of projects across the globe.\"  He said:  \"We know that because the builds of those projects cause this tiny one-liner package to be downloaded more than 47 million times per week.  This is the kind of package you inherit without ever knowing it exists.\"\r\n\r\nLEO:  Yeah.  You don't explicitly call it.  NPM does.\r\n\r\nSTEVE:  No, exactly.  It's down some dependency tree when you're rebuilding the thing that uses it.\r\n\r\nLEO:  Wow.\r\n\r\nSTEVE:  They said:  \"For a short period, it was compromised, turning its massive reach into a ticking time bomb for a significant part of the JavaScript ecosystem.  A single line of malicious code in a package this ubiquitous has a blast radius that is difficult to comprehend.  It has the potential to compromise CI/CD pipelines, production servers, and the laptops of developers at countless companies, from small startups to Fortune 500s.\r\n\r\n\"For us, this global threat did not announce itself with a bang.  It started with a whisper: a cryptic build failure in our pipeline.  The error was ReferenceError: fetch is not defined.  Our investigation into the build failure took a dark turn when we traced it back to this tiny, trusted dependency.  Our package-lock.json clearly specified we were using the stable version 1.3.2.  However, by running npm ls error-ex in our build environment\" - which is going to pull the most recent one - \"we found that version 1.3.3 was being installed.  This version had been published just a day earlier.\r\n\r\n\"Curiosity turned to alarm when we inspected the code of version 1.3.3,\" the malicious one.  \"While version 1.3.2 was a single, clean line of code, the new version contained this JavaScript.\"  And they highlighted in their posting, I've reproduced it here in the show notes, it's just gobbledygook, I mean, it's just junk.\r\n\r\nLEO:  It's obfuscated; right?\r\n\r\nSTEVE:  Yes.  They said:  \"This is heavily obfuscated code, designed to be unreadable.  But buried\" - and I have a lot more to say about that in a minute.  \"But buried within the mess was a function name that made our blood run cold:  'check ethereum w.'  The attacker had injected malware into the package, very likely designed to detect and steal cryptocurrency from the environment it was running in.  The fetch call that was breaking our build was probably the malware attempting to send stolen data to the attacker's server.  Our build failed simply because our Node.js version was old enough not to have a global fetch function.  In a different environment, the attack could have gone completely unnoticed.\"\r\n\r\nOkay, now, the posting continues to talk about this further, but everybody gets the idea.  I went over to NPM to check out the error-ex package.  And in the first place, as I said, as we saw, sure enough, one week in June the error-ex package was downloaded more than 64 million times.  Currently it's at 47,177,455 times per week.  The error-ex package was first released 10 years ago.  Okay?  So it's 10 years old.  It went through a series of post-release updates and quickly stabilized, now having an historical grand total of 16 releases.  Its second-to-last release was nine years ago; and its current release, 1.3.2, which is what everyone is using, is seven years old.  So it has not changed a legitimate byte in the past seven years.\r\n\r\nBut then someone somehow, and actually we now know how, I'll get to that in a second, someone somehow managed to maliciously replace that 1.3.2 release with a bogus 1.3.3 release.  And the dependency managers saw that a newer release had become available and grabbed it so that anyone building anything that used it would be using the latest and the greatest.\r\n\r\nAnd as if the plot were not already thick enough, it gets still thicker because, while the package itself has one single dependency, meaning that it relies upon and pulls in one other package named \"is-arrayish,\" this error-ex package is directly depended upon by 1,544 other packages.  That means that any time any of those 1,544 other packages is rebuilt, and as we know that happens between 47 million and 64 million times per week globally, the repository for this error-ex package would be queried, and the latest and greatest release - meaning now, or while that was active, the malicious version 1.3.3 - would be obtained and incorporated into every single one of those newly rebuilt wholes.\r\n\r\nAt that point that newly rebuilt package whole would have unknowingly and unwittingly incorporated malicious code that apparently looks for and steals its developer's Ethereum cryptocurrency.  And as I said, we'll get to more of that in a second.  The developer who found this wrote, anyone using a newer release of node.js would have had a successful build and would be - and might well still be - completely unaware that their library or application, which they may have then pushed out to who knows whom, now contains malware.\r\n\r\nWe can only be glad that scouting around for Ethereum is all that this thing did because it could have been far more malicious.  And that, of course, takes us back to that recent reporting that the Pentagon is actively using open source software that might be modified maliciously at any time.  We don't know how many of those 1,544 packages may have been rebuilt during the window of opportunity while this malicious 1.3.3 was live.  The repository was immediately rolled back to 1.3.2 as soon as this problem was found.  But with 47 million downloads of this per week, that would have been an average of 6.7 million downloads per day, so that many individual instances of that malware could be in use right now.\r\n\r\nOur takeaway here is that a very nice, open software package-sharing system originally created by and for computer hobbyists has gradually been adopted for serious use all the way up to the Pentagon and everywhere in between.  And at no point has anyone really stopped to say, \"Now, hold on a second.  Is this safe?\"  No one wants it not to be safe because the entire system works so well and is so darned useful.  Right up until the point where it takes a critical missile guidance system offline because a Pentagon subcontractor was building their software the way everyone else is these days.\r\n\r\nSo a note of thanks to our listener, Kevin White, whose email about this arrived while I was assembling the show notes yesterday.  But wait.  There's more.  Or as Jobs might have said, one more thing.  A few hours later I received another note from another listener of ours, Sascha Lopez in South Wales, UK.  That feedback contained a link to the larger story.  Not one, but 18, Leo, extremely popular packages were compromised using this same malware from the same attacker.  Listen to the packages and their weekly download counts:  backslash is 0.26m downloads per week; chalk-template, 3.9m downloads per week; supports-hyperlinks, 19.2m downloads per week; has-ansi, 12.1m downloads per week; simple-swizzle, 26-plus million.\r\n\r\nLEO:  Well, I'm not going to use simple-swizzle anymore.  Gosh darn it.\r\n\r\nSTEVE:  Color-string, 27.48m downloads per week; error-ex, there's our 47m downloads; color-name, 191m downloads per week; is-arrayish, 73.8; slice-ansi, 59.8; color-convert, 193m downloads per week; wrap-ansi, 197, almost 98; ansi-regex, 243.6m downloads per week; supports-color, 287m downloads per week; strip-ansi, 261m downloads per week; chalk, 300m downloads per week; debug, 358m downloads per week; ansi-styles, 371m downloads per week.  All together, these packages have more than two billion downloads per week.\r\n\r\nLEO:  They're not being downloaded by individuals.  I know you explained this, but just for people who are going, well, I don't understand how that could be so.  They're downloaded by automated tools that are building software.  They're updating and - yeah.\r\n\r\nSTEVE:  Updating.  Always pulling the most current version.\r\n\r\nLEO:  So they got - so this tool thinks it's rebuilding something bigger and larger.  And this is the problem that many of these tools have these dependencies built in, and the CI/CD pipeline pulls in these dependencies as it's rebuilding.  And the author or the person who's using those libraries might just be a web designer who said, yeah, I want to include a nice little feature on here, and puts it in his code.  He's not really paying attention to all the other stuff that's being downloaded.\r\n\r\nSTEVE:  And doesn't want to.  I mean, that's part of the benefit of this is you just - it just includes this module, calls some functions of color-string or simple-swizzle, and takes advantage of whatever that package does.\r\n\r\nLEO:  He's probably not even calling it himself.  It's this package that's calling it.\r\n\r\nSTEVE:  Right.\r\n\r\nLEO:  I've seen, you see this all the time where you install a package - and this is a real problem, by the way, in all of these systems - and then they go out and get 50 dependencies.\r\n\r\nSTEVE:  Yup.\r\n\r\nLEO:  And install them.\r\n\r\nSTEVE:  Well, and we talked about this back with the log4j problem because that was the problem with log4j...\r\n\r\nLEO:  Everybody used it.\r\n\r\nSTEVE:  ...in the library that everything else was using.  So it wasn't until all of those other packages would be rebuilt that the problem would be able to get out of the system.  So here's what we know.  We know what happened.  The maintainers of those packages were phished, plain and simple.\r\n\r\nLEO:  Yeah, it has to be because you can't commit into these packages unless you have commit privileges.\r\n\r\nSTEVE:  Yes.  They got phished.  Okay.  So now we know what this is.  All these packages were maliciously updated to contain code that would be executed on the client of a website, which silently intercepts crypto, that is, the malware silently intercepts crypto and Web3 activity in the browser, manipulates wallet interactions, and rewrites payment destinations on the fly so that funds and approvals are redirected to attacker-controlled accounts without any obvious signs to the user.  So this is a massive attack on cryptocurrency wallets, anything web hosted.\r\n\r\nThe malware, which has now been fully reverse-engineered, turns out to be extremely sophisticated.  It's a browser-based interceptor that hijacks both network traffic and application APIs.  It injects itself into functions like fetch, XMLHttpRequest - which is how browsers do remote queries - and common wallet interfaces, then silently rewrites values in requests and responses.  That means any sensitive identifiers, such as payment destinations or approval targets, can be swapped out for attacker-controlled values before the user even sees or signs them.  To make the changes harder to notice, it uses string-matching logic that replaces targets with look-alike values.\r\n\r\nIt's extra dangerous because it operates at multiple layers:  altering content shown on websites, tampering with API calls, and manipulating what users' apps believe they are signing.  Even if the interface looks correct, the underlying transaction can be redirected in the background.\r\n\r\nOne of the maintainers who was compromised explained that he had been phished.  He wrote about this and sent a screenshot from the email, which I have in the show notes.  It says:  \"Hi, qix (Q-I-X).  As part of our ongoing commitment\" - oh, this appeared to come from NPM themselves legitimately.  \"As part of our ongoing commitment to account security, we are requesting that all users update their Two-Factor Authentication credentials.  Our records indicate that it has been over 12 months since your last Two-Factor Authentication update.\r\n\r\n\"To maintain the security and integrity of your account, we kindly ask that you complete this update at your earliest convenience.  Please note that accounts with outdated 2FA credentials will be temporarily locked starting September 10th\" - okay, today is the 9th.  This all happened yesterday on the 8th - \"to prevent unauthorized access.\"  And then there's a link:  Update 2FA Now.  It said:  \"If you have any questions or require assistance, our support team is available to help.  You may contact us through this link.\" \r\n\r\nSo note that one of the giveaways of the phishing email is the cutoff date, just two days from the notice date.\r\n\r\nLEO:  Urgency.  Very important.  Yup.\r\n\r\nSTEVE:  Creating a sense of urgency is one of the ways to get recipients to forget their own safety protocols.  And get this.  The domain from which the email had been sent, which appeared to be NPM themselves, it was npm.js.com...\r\n\r\nLEO:  Gee, that sounds right.\r\n\r\nSTEVE:  ...had just been registered three days before.\r\n\r\nLEO:  Oh, god.\r\n\r\nSTEVE:  On September 5th.  So here's another example of an instance where checking the registration duration of anything we're replying to or relying upon is such a simple thing to do and really represents powerful protection.  We keep seeing that attacking domains are very fresh.  They've just been registered.  I look forward to the day when our browsers and our email clients start putting a big red flag in front of us saying, \"Whoa, just so you know, this domain is three days old.  Does that make sense to you?\"\r\n\r\nLEO:  Yeah, that's what NextDNS does.  And I turned it off because there were sites that I wanted to access that were brand new.  And then I realized, maybe I should turn that back on again.\r\n\r\nSTEVE:  Yeah.  I think, you know, just clicking through those makes sense.  And, you know, pausing to ask whether there's something there makes sense.  So the fate of many hundreds of millions of users of this handful of 18 NPM packages critically - think about that - critically depends upon the package maintainers not falling for basic phishing attacks.  Basically, this is - think about how similar this is to the certificate authority model, which is, you know, really struggles and works at maintaining its security.\r\n\r\nHowever, there we have a relatively small number of trusted root authorities that are able to be all - that know that their existence, that their trust relies upon not making a mistake.  Here we've got the guy in Nebraska who's maintaining the random one-line error-ex package, and oops, up pops a note, and he doesn't want to get locked out, so he clicks the Update 2FA and ends up turning his credentials over, loses control of his repository, malware gets injected, and two billion downloads a week.  So I don't...\r\n\r\nLEO:  And this is the problem in general is that we've got all of these automated systems to make our life easier.  You know, when you want to install something using Docker, it downloads a manifest, and you just watch it as it downloads stuff, loads stuff...\r\n\r\nSTEVE:  All the stuff spews by.\r\n\r\nLEO:  And now it's just great.  Boy, that was easy.  So we should review all this, I guess.\r\n\r\nSTEVE:  I know.  As I started off saying, without ever intending to, and with only ever having the most altruistic and best of intentions, we have slowly over time built, not just a house of cards, but a massive kingdom castle out of cards.  It's a system that we cannot stop using because over time we've become utterly dependent upon it.  Yet its security, which is to say its frankly shameful lack of security, I mean, actual security, really ought to be keeping anyone who's using it up at night.  You know, everyone has only the best of intentions.  Of that there's no doubt.  But, you know, an old familiar saying might apply here.  The road to hell is paved with good intentions.  And unfortunately, we have a system that everybody is using, and it's just not secure.\r\n\r\nOne piece of listener feedback from Bill Allen.  He said:  \"The mention of BYTE Magazine in SN-1041 caused me to remember how I became introduced to SpinRite in the first place.  1988 was the year I upgraded my dual floppy drive IBM/XT clone PC to a 32MB MFM/RLL MiniScribe drive.\"  Yup.  Remember that.  I had one of those, too.  He said:  \"I was desperate to maintain it, optimize it, and otherwise keep it alive.  I was also already a subscriber to BYTE magazine.  I now remember reading that review article about SpinRite and right away contacted GRC to get a copy.  I know I started with SpinRite 1, so that seems about the right time frame.\r\n\r\n\"Anyways, that was a welcome trip down memory lane.  I am still using SpinRite today with version 6.1 and have introduced it over the years to new generations of technicians.  There is a little sadness in all this, though, as it also reminded me of the sudden demise of BYTE magazine in 1998.  I remember being rather devastated, since it was my primary source of tech news and views at the time.\"  He said:  \"Here is a bit on that from Tom R. Halfhill, BYTE Magazine senior editor, 1992-1998.\"  And he includes a link in his note, signing off \"Best Regards, Bill Allen, Crowley, TX | SpinRite 1, SN 1.\"\r\n\r\nSo the link that Bill provided is very interesting to anyone who loved BYTE magazine.  The page explains the sequence of events surrounding the end of BYTE Magazine in detail, which amounts to CMP purchasing all of McGraw-Hill's publications and just not caring about BYTE Magazine.  But, for example, it mentions our old friend Jerry Pournelle, writing:  \"After the 1998 shutdown, the BYTE website continued to draw about 600,000 page views a month, even without ever being updated.  Obviously, many people still wanted the kind of information BYTE provided.  This unrelenting traffic prompted CMP to revive BYTE as a web-only publication in 1999.\r\n\r\n\"CMP convinced longtime BYTE columnist Jerry Pournelle to resume his Chaos Manor column on the new Byte.com website, lending some credibility to the effort.  However, Pournelle left Byte.com in 2006.  The underfunded website lacked BYTE Magazine's breadth and depth of technical content, and it vanished in 2009.\"\r\n\r\nSo anyway, there's much more there, including a detailed FAQ created by, as Bill noted, Tom Halfhill, then the senior editor of BYTE Magazine's print edition at the time of its demise.  I invite anyone who might be curious to follow the link in Bill's feedback.  And thank you, Bill.  Although BYTE magazine might not still be around and able to help, I'm delighted that SpinRite still is, and I have some big plans for its future.\r\n\r\nLEO:  Yeah.  I remember...\r\n\r\nSTEVE:  Keep scrolling, Leo.  There's an FAQ there.\r\n\r\nLEO:  Oh, great.\r\n\r\nSTEVE:  Like what happened, about the layoffs.  Apparently everybody got fired two days before it was shut down with, like, no notice.\r\n\r\nLEO:  Yeah.  It's sad.\r\n\r\nSTEVE:  And one techie was allowed to stay, and he resigned in protest because it's like, I'm not going to stay here when all my friends have just been laid off.\r\n\r\nLEO:  And Byte.com was actually pretty awful, I remember.\r\n\r\nSTEVE:  I think that's the case.  I imagine that Jerry just did it because he had the habit, and they probably paid him something for a while.\r\n\r\nLEO:  Yeah.  Yeah, exactly, yeah.  Yeah, I think they suckered him a little bit, yeah.\r\n\r\nSTEVE:  Yeah.  Okay.  We're going to talk about Letters of Marque after our last sponsor.\r\n\r\nLEO:  Oh, good.\r\n\r\nSTEVE:  And look at what happens when the government might be giving our private companies the permission to attack the people who are attacking them.\r\n\r\nLEO:  To be privateers.\r\n\r\nSTEVE:  It's even worse than that, Leo.  It goes way beyond that.\r\n\r\nLEO:  Oh, I can't wait.  This is fascinating. \r\n\r\nSTEVE:  So one of the interesting and somewhat delicate topics we've touched on from time to time is the question of whether, and if so when, it might be okay for good guys to do things that are not technically legal, but with good intent, and for a hopefully good cause and outcome.  In other words, making the world a better place, even if the means to do so would mean breaking a few rules along the way.  \r\n\r\nAn early instance of this was way back in the Internet worms era with the likes of Code Red and Nimda.  In those cases, compromised servers were actively scanning for other servers that had not yet been compromised.  And the source IPs of those scans were not being and could not be spoofed.  As a consequence, security firms who were running honeypots were collecting a comprehensive list of worm-compromised servers since compromised servers were reaching out at random to see whether or not an as-yet compromised server might reside at some given IP address.\r\n\r\nSo the question then became, would it be okay for the good guys to use the same now well-known flaw in Microsoft's IIS server which was enabling the worms in the first place to reach out and proactively and remotely disinfect that machine.  A bad worm had infected it.  Why couldn't someone who knew where an infected machine was located by its IP address on the Internet reverse that and disinfect it?\r\n\r\nI was participating on the conference call with Washington when that idea was floated to the proper person at the Department of Justice at the time.  She made it quite clear that doing so would be against the law, plain and simple.  And in listening to her carefully, it was clearly not a wink-wink.  She was not saying \"no\" but hoping that we would go ahead and do it anyway.  This was not one of those \"Let's not ask for permission, we'll ask for forgiveness\" instances.\r\n\r\nAnd since then, there have been many other instances where it is so tempting to allow good guys to remotely fix problems that they almost certainly could.  How many consumer routers have been found to be vulnerable?  How many random application packages could be patched with the knowledge of a problem before that problem's public release?  When Plex found a critical remotely exploitable vulnerability in its publicly exposed media server, it could have proactively reached out and fixed it before bad guys were able to use that flaw to install a keystroke logger into a LastPass developer's machine at home and give LastPass the biggest black eye of its life.\r\n\r\nIn most cases, anything a bad guy can do remotely, a good guy could remotely patch to close the backdoor long before bad guys are given the information they need in the first place.  But it doesn't happen because it's just as illegal for good guys to hack a network - even if the intention is to help that network's owner - as it is for bad guys to hack the same network.  And that's the way things have been since the beginning of all this global networking business.\r\n\r\nWe're talking about this today because under our current political administration things may be changing.  Anyone who's been following U.S. news will likely have heard that President Trump has decided to rename the U.S. Department of Defense the Department of War.  That certainly reflects a change in attitudes somewhere.  And I was put in mind of all this when I saw a story in CyberScoop carrying the headline \"Google previews cyber 'disruption unit' as U.S. government and industry weigh going heavier on offense.\"  And the teaser at the top of their story notes:  \"There are still impediments to overcome before companies and agencies can get more broadly aggressive in cyberspace, both legal and commercial.\"\r\n\r\n\"Impediments.\"  I'll say.  Like all those pesky laws we were just talking about.  Since this could change everything we know about the status quo, I want to share what CyberScoop wrote. They said:  \"Google says it is starting a cyber 'disruption unit,' a development that arrives in a potentially shifting U.S. landscape toward more offensive-oriented approaches in cyberspace.  But the contours of that larger shift are still unclear, as is whether or not and to what extent it's even possible.  While there's some momentum in policymaking and industry circles to put a greater emphasis on more aggressive strategies and tactics to respond to cyberattacks, there are also major barriers.\r\n\r\n\"Sandra Joyce is the vice president of Google' Threat Intelligence Group.\"  That's TIG who, as we noted earlier has recently been extorted to fire those two guys.  \"She said at a conference last Tuesday that more details of the disruption unit would be forthcoming in future months, but the company was looking for 'legal and ethical disruption' options as part of the unit's work.  She said at the Center\" - and we'll be talking about this a lot, CCPL - the \"Center for Cybersecurity Policy and Law event, where she called for partners in the project:  'What we're doing in the Google Threat Intelligence Group is intelligence-led proactive identification of opportunities where we can actually take down some type of campaign or operation.  We have to get from a reactive position to a proactive one if we're going to make a difference right now.'\"\r\n\r\nCyberScoop wrote:  \"The boundaries in the cyber domain between actions considered 'cyber offense' and those meant to deter cyberattacks are often unclear.  The tradeoff between 'active defense' vs. 'hacking back' is a common dividing line.  On the less aggressive end, 'active defense' can include tactics like setting up honeypots designed to lure and trick attackers.  At the more extreme end, 'hacking back' would typically involve actions that attempt to deliberately destroy an attacker's systems or networks.  Disruption operations might fall between the two, like Microsoft taking down botnet infrastructure in court, or the Justice Department seizing stolen cryptocurrency from hackers.\r\n\r\n\"Trump administration officials and some in Congress have been advocating for the U.S. government to go on offense in cyberspace, saying that foreign hackers and criminals are not suffering sufficient consequences.  Much-criticized legislation to authorize private sector 'hacking back' has long stalled in Congress, but some have recently pushed a version of the idea where the President would issue 'letters of marque' like those for early U.S. sea privateers to companies, authorizing them to legally conduct offensive cyber operations currently forbidden under U.S. law.\"\r\n\r\nWhoa.  So this would not be getting a \"get out of jail free card.\"  This would be a preemptive pardon for anything illegal that might be done in the security interests of the United States.  So at this point I was curious about these \"letters of marque.\"  So I asked our AI Oracle about them and learned the following.\r\n\r\nIt said:  \"A letter of marque is an old legal instrument from the age of the sail.  It was essentially a government license authorizing a private shipowner (a 'privateer') to arm their vessel and attack the shipping of an enemy nation during wartime.  Marque means 'seizure.'  The letter granted the holder the right to capture enemy vessels and cargo.  The captured ships (called 'prizes') would then be brought back to port, condemned in a prize court, and sold, with profits shared between the privateer and the government.  The system blurred the line between the Navy and piracy.  Without a letter, you were a pirate; with one, you were a lawful privateer.\r\n\r\n\"In the U.S. context, the U.S. Constitution (Article I, Section 8) explicitly gives Congress the power 'to declare war, grant letters of marque and reprisal, and make rules concerning captures on land and water.'  So legally, only Congress  not the President  can authorize letters of marque.  That means the phrase 'Presidential letter of marque' is technically a misnomer.  The President cannot independently issue them.  Congress would have to approve.\"\r\n\r\nNow, the reason ChatGPT offered that was that, not knowing any better, and following from CyberScoop's article which said that \"some have recently pushed a version of the idea where the President would issue 'letters of marque,'\" my questioning prompt to ChatGPT was:  \"What is a Presidential letter of marque?\"  As we learned, there is no such thing.  On the other hand, our experience during President Trump's second term suggests that this President would not let that stop him.\r\n\r\nFinishing up with ChatGPT's reply, because it's interesting, it said:  \"The last U.S. letters of marque were issued during the War of 1812.  After that, the U.S. Navy became strong enough that privateering was no longer needed.  International law (the 1856 Declaration of Paris) abolished privateering among most major powers.  The U.S. never signed, but has honored the ban in practice.\"  In modern discussions, you'll sometimes hear about reviving letters of marque in the context of cybersecurity, for example, allowing private companies to take offensive action against foreign hackers.  But that's purely theoretical and would require an act of Congress.\r\n\r\nSo to answer directly:  A \"Presidential letter of marque\" would be a government license to privately wage war on behalf of the United States.  But under U.S. law, the President alone has no authority to issue one.  It would require Congressional authorization.  Except, of course, that our current president has shown himself to be quite willing to retest many of the nation's longstanding protocols and assumptions.  Our Supreme Court as a consequence has been unusually busy.\r\n\r\nReturning to CyberScoop's reporting, they wrote:  \"Experts say that the private sector has some catching up to do if there's to be a worthy field of firms able to focus on offense.  John Keefe, a former National Security Council official from 2022 to '24 and National Security Agency (NSA) official before that, said there had been government talks about a 'narrow' letters of marque approach 'with the private sector companies that we thought had the capabilities.'  The concept was centered on ransomware, Russia, and rules of the road for those companies to operate.  Speaking like others in this story at Tuesday's conference, Keefe said:  'It wasn't going to be the Wild West.'\r\n\r\n\"Joe McCaffrey, Chief Information Security Officer at defense tech company Anduril Industries said that the companies with an emphasis on offense largely have only one customer, and that's governments.  He said:  'It's a really tough business to be in. If you develop an exploit, you get to sell to one person legally, and then it gets burned, and you're back again.'\"  And that actually is what we talked about recently about the whole government market for zero-days.\r\n\r\nSo CyberScoop said:  \"'By their nature, offensive cyber operations in the federal government are very time- and manpower-intensive,' said Brandon Wales, a former top official at the Cybersecurity and Infrastructure Security Agency (CISA) and now Vice President of Cybersecurity at SentinelOne.  'Private sector companies could make their mark by innovating ways to speed up and expand the number of those operations,' he said.  Overall, among the options of companies that could do more offensive work, Andrew McClure, managing director at Forgepoint Capital said:  'The industry doesn't exist yet, but I think it's coming.'  Brandon Wales, now at SentinelOne, said that Congress would have to clarify what companies are able to do legally as well.\r\n\r\n\"But that's just the industry side.  There's plenty more to weigh when stepping up offense.  Megan Stifel, Chief Strategy Officer for the Institute for Security and Technology, said:  'However we start, we need to make sure that we are having the ability to measure impact.  Is this working?  And how do we know?'\r\n\r\n\"If there was a consensus at the conference, it's that the United States  be it the government or the private sector  needs to be doing more to deter adversaries in cyberspace by going after them more in cyberspace.  One knock on the idea has been that the United States can least afford to get into a cyber shooting match, since it's more reliant on tech than other nations, and an escalation would hurt the U.S. the most by presenting more vulnerable targets for enemies.  But Dmitri Alperovitch, chairman of the Silverado Policy Accelerator, said that idea was wrong for a couple of reasons, among them that other nations have become just as reliant on tech, too.\r\n\r\n\"And 'The very idea that in this current bleak state of affairs, engaging in cyber offense is escalatory, I propose to you, is laughable,' he said.  'After all, what are our adversaries going to escalate to in response?  Ransom more of our hospitals?  Penetrate more of our water and electric utilities?  Steal even more of our intellectual property and financial assets?'  Alperovitch continued:  'Not only is engaging in thoughtful and careful cyber offense not escalatory, but not doing so would be.'\"\r\n\r\nOkay.  So this was just one article in CyberScoop.  But the consequences of this recent conference captured the attention of the entire industry.  Three days ago in Lawfare the headline was \"Google Sharpens Its Cyber Knife.\"  Four days ago, the publication Today's General Counsel's headline was \"Google is Forming a Cyber Disruption Unit.\"  Also four days ago, OODAloop.com:  \"The Perils of Precedent:  Could Google's Disruption Unit Invite Retaliation?\"  Five days ago in SC Media:  \"Google to launch cyber disruption unit.\"\r\n\r\nSix days ago, the Digital Watch Observatory's headline was \"Disruption unit planned by Google to boost proactive cyber defense.\"  Seven days ago in Homeland Security Today:  \"Google Previews Cyber Disruption Unit as U.S. Debates Stronger Offensive Measures.\"  Even Tom's Hardware back on August 28th carried the headline:  \"Google is getting ready to 'hack back' as U.S. considers shifting from cyber defense to offense.\"\r\n\r\nSo from the perspective of someone keeping up on cybersecurity news here in the U.S., it does feel very much as if we are under continual assault from what we are told are aggressive and hostile state-sponsored hackers operating out of Russia, China, and North Korea.  We know that hospitals and schools are being hacked, having their networks taken down and their services, whether it be healthcare or education, impacted and interrupted.  And we know that our U.S. corporations now live under the constant threat that some well-meaning but momentarily inattentive employee may click on a link they receive in email which results in a network compromise, the exfiltration of the corporation's data, exposure to extortion demands, and public humiliation followed by shareholder lawsuits.\r\n\r\nSo, no way do I, or I'm sure anyone, think that public or private entities in the U.S. should indiscriminately attack Chinese, Russian, or North Korean institutions or enterprises.  That's not us.  And I was assuming that was not what anyone was talking about.  It doesn't sound like Google is.  But there is an area of this that makes me feel somewhat queasy, which is the use of the term \"retaliation.\"  That term is being bandied about in Washington policy circles.  It's one thing for Google to \"disrupt\" an adversarial attacker's illegal operation which is in the process of attacking us.  I'd be inclined to call that \"very proactive defense.\"  But it's another thing entirely to use the threat of wholesale unfocused reprisal as a deterrent - which is also being discussed.\r\n\r\nThe conference that recently brought all this to a head was held by the Center for Cybersecurity Policy and Law, which I mentioned is the CCPL, exactly two weeks ago on August 26th.  The conference announcement said:  \"CCPL will convene cybersecurity leaders from government, industry, and policy disciplines to delve into core questions raised in the recent CCPL report 'To Hack Back, or Not Hack Back?  That is the Question.  Or is it?'\"\r\n\r\nOkay.  So I've linked to this seven-page PDF in the show notes.  And for anyone who is interested in this whole topic, believe me, this report will not bore you.  It's quite chilling.  Under its section \"Why are we talking about this now?\" the report writes:  \"The arrival of a new administration and the growing complexity of the cyberthreat landscape have reignited discussions around the use of offensive cyber operations.  The White House has suggested that such tactics could be a valuable part of the U.S. national security toolkit, particularly to counter cyberthreats from China.  Proponents highlight major incidents, including the Salt Typhoon and Volt Typhoon campaigns and the recent breach of the U.S. Department of the Treasury, as clear indications that stronger deterrence measures are necessary to combat cybercriminals and state-sponsored threat actors.\r\n\r\n\"Though not a new debate,\" they write, \"some senior officials and agencies are signaling renewed interest in expanding offensive cyber capabilities, including potential involvement by the private sector.  The U.S. Cyber Command (USCYBERCOM) has emphasized the need for more proactive actions, especially in defending critical infrastructure.  The goal is to use offensive cyber tools, not just in retaliation, but also as a deterrent to prevent future attacks.\"\r\n\r\nOkay, now, I hope it's clear to everyone that this really changes the game.  Maybe it's a good thing.  I can't judge that.  Perhaps officials in China, Russia, and North Korea have been laughing at the U.S. and at our quaint Constitution which so often ties our hands and prevents ad hoc retaliation during a fit of pique.  If that's been the case historically, I would at least imagine that they are likely laughing less loudly with President Trump sitting in the Oval Office where \"fits of pique\" appear to be the order of the day.  If having President Trump's finger on the button gives them pause, it's not clear to me that's a bad thing.\r\n\r\nBut to be very clear, what this policy exploration paper is examining is not some Google disruption of a specific targeted foreign criminal enterprise.  It's exploring a significant escalation in U.S. cyber posture.  The \"Why are we talking about this now?\" section of the paper continues, saying:  \"Pentagon Acting Chief Information Officer Katie Arrington stated her role includes removing policy barriers that limit the Department of Defense\" - now known as the Department of War - \"ability to counter adversaries, stressing the need for enhanced offensive capabilities.\r\n\r\n\"Similarly, CIA Director John Ratcliffe has expressed support for developing offensive cyber tools and establishing a comprehensive cyber deterrence strategy.  Former National Security Advisor Mike Waltz has also endorsed the use of offensive cyber operations to impose greater costs on threat actors like China.\r\n\r\n\"Katie Sutton, the nominee for Assistant Secretary of Defense for Cyber Policy, pledged during her confirmation hearing to review National Security Policy Memorandum-13\" - that's actually kind of infamous, it's referred to in that seven-page document - \"which governs the DoD's authority to conduct offensive cyber operations.  Originally issued under the Trump Administration in 2018 and revised by the Biden Administration in 2022, NSPM-13 provides 'well-defined authorities to the Secretary of Defense'\" - now actually known as the Secretary of War - \"'to conduct time-sensitive military operations in cyberspace,' according to a 2020 speech given by Paul Ney, the former DoD general counsel.\r\n\r\n\"Congress is also revisiting the role of offensive cyber operations.\"  Congress is.  \"Although the bipartisan 'Active Cyber Defense Certainty Act' introduced in 2019 by Rep. Tom Graves failed to pass the 116th Congress, it has helped revive the debate.  The bill aimed to amend the Computer Fraud and Abuse Act to grant legal authority for organizations to engage in active cyber defense\" - active cyber defense - \"including offensive measures, to protect their networks.\"\r\n\r\nOkay, now, none of us are on the inside in the way these government officials are.  So it's not possible to fairly armchair quarterback what they want to do, to judge how much more freedom they need and what they would do with what they were given.  And it does appear that even if President Trump were to issue letters of marque, they would only be serving as a bridge to where it certainly does appear the country's current intelligence and defense agency heads and many legislators want to take the country.  Sentiment appears to be moving in a cyber-aggressive direction.\r\n\r\nAnd as for cyber as a deterrent, I'm not sure about that.  I don't like the idea of any conflict being escalated, whether cyber or conventional.  The U.S. has a massive conventional military that we've been relatively restrained in deploying.  And it's likely that the knowledge of its potentially overwhelming strength has served as an effective deterrent to those who have ambitions to exercise more of their own lesser power.\r\n\r\nThe problem is, military parades appear to attempt to demonstrate impressive military hardware, which is visible and can be counted, as can stockpiles of weapons and warheads.  It's not clear to me that cyber is at all the same.  Can having an impressive cyber capability form a deterrent?  I don't see how.  Having warheads whose permanent destructive potential is well understood, along with a fail-safe system for their deployment, can serve as a powerful deterrent because they do not need to be used to be appreciated.\r\n\r\nBy comparison, the only way to appreciate a nation's cyber-offensive capability is for it to be used against an adversary.  That's not the definition of a deterrent.  In that sense cyber capabilities unfortunately are more like biological weapons which the various super-powers all assume each other have, but no one dares to use.  They're not something that can be paraded in the streets or counted in silos.  They are simply feared while their existence is adamantly denied.\r\n\r\nFollowing that analogy, fear of what such a weapon might do if it were ever to be released does serve as a deterrent, I suppose.  So might the various other cyberwarfare nations - China, Russia, and North Korea - be fearful of the United States' cyberwarfare capabilities?  I have no idea.  As I said at the top, this entire area of offensive cyberwar is largely classified, unknown, uncomfortable, and unexplored territory whose exploration produces more questions than answers. It is also, as they say, and as I said, far above my pay grade.\r\n\r\nI am much more comfortable exploring browser cookies, certificate revocations, and the mechanics of other tangible technologies.  But the fact is, conferences like the one that was just held two weeks ago today, during which Google announced their formation of a \"disruption unit,\" are occurring; and as all the other headlines clearly showed, it's big news.  So as uncomfortable as it may be, and as many questions as we may be left with, I think we should at least be aware of what's percolating out there on the cyberwarfare front.  It may well change the way the world is organized.\r\n\r\nLEO:  So it's an interesting question.  I mean, when you compare it to biological warfare, you know, there's a very clear - we have a long tradition with the Geneva Conventions and other agreements between nations of staying away from stuff that could really escalate into something nightmarish.\r\n\r\nSTEVE:  Right.\r\n\r\nLEO:  Do you feel that cyberwarfare is that risky?\r\n\r\nSTEVE:  There's a little bit of a problem with containment, I think.  I mean, okay.  So say, for example, that the U.S. has the ability to shut off the electrical power for Beijing.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  It would be a huge embarrassment.  If it was to actually happen, deaths would occur; right?  If, like, all power, I mean, [crosstalk]...\r\n\r\nLEO:  It would be an act of war.\r\n\r\nSTEVE:  It would be an act of war, yes.  And, I mean, and so it's extremely escalatory by nature.  Now, so maybe you do something smaller.  You shut off the power for a small province somewhere that's, like, you know...\r\n\r\nLEO:  Almost do a demonstration to show that we have the capability.  Don't - see, I think that I - it's an interesting - such a conundrum.\r\n\r\nSTEVE:  Maybe we attack a lesser country that, you know...\r\n\r\nLEO:  Well, we did that when the Ukraine war began.  We engaged in offensive cyberwarfare on their behalf.  We know we did that.  And I suspect that that's one of the things the Ukraine war has been all along is a proxy for these superpowers to demonstrate capabilities.\r\n\r\nSTEVE:  Right.\r\n\r\nLEO:  In an attempt to deter each other.\r\n\r\nSTEVE:  Right.  \r\n\r\nLEO:  Right?\r\n\r\nSTEVE:  We don't want you to go any further, Vladimir, you know, we're not happy with you getting closer to the NATO borders.  So, you know...\r\n\r\nLEO:  Right, right.  And the risk is, if you do it on a large scale, look, the Chinese are probably much more able to disrupt our grid than we are to disrupt their grid; right?\r\n\r\nSTEVE:  That's my worry is, you know...\r\n\r\nLEO:  Yeah.\r\n\r\nSTEVE:  And so we only have a U.S.-centric view.  And I talk about that all the time.  We know how much we're being attacked.  I don't know, well, and I don't think that, I mean - and they're attacking us indiscriminately; right?  They're state-sponsored, and they're ransoming our enterprises.  They're attacking our hospitals and our school systems.  I mean, I hope we're not doing that.  That's, I mean, that's disgusting.\r\n\r\nLEO:  Yeah, that's the other thing is that, you know, we often believe that we in the United States have a higher calling and don't want to engage in...\r\n\r\nSTEVE:  Right, that pesky Constitution.\r\n\r\nLEO:  Yeah.  But at the same time I can understand the urge, and I do feel you're right that where we stand right now, I mean, just nicknaming the Department of Defense \"Department of War\" kind of tells it, says it all.  We are in very much of a saber-rattling situation.  And I'm sure there are people in the government who are saying let's go, let's go, why are we not doing it, regardless of the consequences.  I think the sensible thing would be to demonstrate the capability as a deterrent.  Just as you hope [crosstalk].\r\n\r\nSTEVE:  And then how do you?\r\n\r\nLEO:  Well, you do things like small-scale, targeted, and you do them in a way that is clearly a demonstration.  So you don't, you know, it would be enough to put on Vladimir's screen, \"Hey, we're watching you, so knock it off.\"  That would harm no one.  But it would be an effective demonstration of our capabilities.  I think there are ways...\r\n\r\nSTEVE:  Unfortunately, Russia is still on the Internet.  It would be nice if we just denied, just like Russia being an Internet black hole.\r\n\r\nLEO:  Well, that's what - I don't think you want to do something so dramatic.  I think what you want to do, and I think there are ample opportunities to do this in cyberwarfare, is demonstrate a capability and then say, so what - that's effective, I would think.  And it is, as you say, having a...\r\n\r\nSTEVE:  Well, a beautiful example is what we did with Stuxnet.  The world went, oh, my goodness.\r\n\r\nLEO:  Right.\r\n\r\nSTEVE:  You know.\r\n\r\nLEO:  Well, Israel has very clearly shown that it has a broad range of offensive capabilities.\r\n\r\nSTEVE:  Pagers exploding and, you know, being targeted by your bodyguards [crosstalk] cell phone.\r\n\r\nLEO:  But even Israel is reluctant to do some kind of - engage in wholesale cyberwarfare.\r\n\r\nSTEVE:  To show all their cards.\r\n\r\nLEO:  Yeah.\r\n\r\nSTEVE:  Right.\r\n\r\nLEO:  Because it's dangerous.  It escalates.  It gets out of control.  And we are as - this is the real point is we are as vulnerable as anybody, maybe more so.  So it would eventually come back to us.  This paper you refer to, which is very interesting, has a number of risks, including collateral damage, you know, and risk of retaliation.  And I think those are very serious concerns.  I hope that the people who are in charge of this pay attention to this.  I think the worst thing to do would be to give private companies this capability.  We should, just as we don't give private companies nuclear weapons and tanks, we should - this is something that government should be responsible for and should develop this capability and not give letters of marque.\r\n\r\nSTEVE:  If effort were put into securing what we have, the way we talk about being able to do all the time, I mean, all we have to do is fix the security of our border devices.\r\n\r\nLEO:  But we have issues with our grid because the way we set up the grid there is no national grid.\r\n\r\nSTEVE:  Yup.  Yup.\r\n\r\nLEO:  And so it's privately held by a vast number of smaller companies with differing priorities.\r\n\r\nSTEVE:  Yeah, and we've also talked about how there is load-sharing across sub-grid boundaries.  And if you take out a chunk of it, there is a cascading effect.\r\n\r\nLEO:  We've seen it happen.\r\n\r\nSTEVE:  Yes.\r\n\r\nLEO:  We've seen it happen.  So I think we are vulnerable.  And I think that we should be very - you're right.  That's the NSA's mission.  It's a twofold mission.  One is to protect us, and it is the other to develop offensive weapons, which they are doing.  I mean, we know they do it from the Snowden revelations.  We know they do it.  And I hope they're doing their job.  But I hope we don't engage in outright cyberwarfare because that would not end well for anybody.\r\n\r\nSTEVE:  Well, as you know, I have been approached and said no.\r\n\r\nLEO:  Yeah.  You're like \"Good Will Hunting.\"  You say no, I'm not going to work for the NSA.\r\n\r\nSTEVE:  I just, I'm sorry.\r\n\r\nLEO:  It's a really interesting subject.  And I do hope sanity and cooler heads prevail because the risks are high.  Just as they are to using nuclear biological weapons.  It's a dangerous, dangerous game.\r\n\r\nSTEVE:  Yeah.  I worry that there's a sense of nothing explodes in the same way that a bomb does.  You know, it seems like, oh, well, my aunt got hacked, and she's fine.  It's like, oh, okay, careful.\r\n\r\nLEO:  I suspect that the next five years, and we'll be here to report it, there will be an incident created by a nation-state that will be dramatic and very provocative and perhaps cause loss, great loss of life.  That will be considered an act of war, just as 9/11 was.  And I fear the result of that.  I think we're going to see that in the next few years.  We'll be here to talk about it.\r\n\r\nSTEVE:  During the podcast lifetime.\r\n\r\nLEO:  Yeah, during the podcast lifetime.  I really do.  The only way to win is not to play the game. \r\n\r\nCopyright (c) 2025 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  https://creativecommons.org/licenses/by-nc-sa/2.5/.\r\n\r\n",
  "participants": "Steve Gibson & Leo Laporte\r",
  "tags": [
    "Encryption",
    "Microsoft",
    "Security"
  ],
  "title": "Letters of Marque\r",
  "file_name": "sn-1042.txt"
}
